{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 二値分類：映画レビュー\n",
    "\n",
    "映画レビューのテキストの内容に基づいて、肯定的なレビューと否定的なレビューに分類"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDbデータセット\n",
    "\n",
    "Internet Movie Database（IMDb）：  \n",
    "- 訓練用の25,000件のレビューとテスト用の25,000件のレビューで構成\n",
    "- 否定的なレビュー50%と肯定的なレビュー50%で構成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.datasets import imdb\n",
    "\n",
    "# 訓練データにおいて出現頻度の高い10,000個の単語のみ残し、IMDbロード\n",
    "(train_data, train_labels), (test_data, test_labels) = imdb.load_data(num_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([list([1, 14, 22, 16, 43, 530, 973, 1622, 1385, 65, 458, 4468, 66, 3941, 4, 173, 36, 256, 5, 25, 100, 43, 838, 112, 50, 670, 2, 9, 35, 480, 284, 5, 150, 4, 172, 112, 167, 2, 336, 385, 39, 4, 172, 4536, 1111, 17, 546, 38, 13, 447, 4, 192, 50, 16, 6, 147, 2025, 19, 14, 22, 4, 1920, 4613, 469, 4, 22, 71, 87, 12, 16, 43, 530, 38, 76, 15, 13, 1247, 4, 22, 17, 515, 17, 12, 16, 626, 18, 2, 5, 62, 386, 12, 8, 316, 8, 106, 5, 4, 2223, 5244, 16, 480, 66, 3785, 33, 4, 130, 12, 16, 38, 619, 5, 25, 124, 51, 36, 135, 48, 25, 1415, 33, 6, 22, 12, 215, 28, 77, 52, 5, 14, 407, 16, 82, 2, 8, 4, 107, 117, 5952, 15, 256, 4, 2, 7, 3766, 5, 723, 36, 71, 43, 530, 476, 26, 400, 317, 46, 7, 4, 2, 1029, 13, 104, 88, 4, 381, 15, 297, 98, 32, 2071, 56, 26, 141, 6, 194, 7486, 18, 4, 226, 22, 21, 134, 476, 26, 480, 5, 144, 30, 5535, 18, 51, 36, 28, 224, 92, 25, 104, 4, 226, 65, 16, 38, 1334, 88, 12, 16, 283, 5, 16, 4472, 113, 103, 32, 15, 16, 5345, 19, 178, 32]),\n",
       "       list([1, 194, 1153, 194, 8255, 78, 228, 5, 6, 1463, 4369, 5012, 134, 26, 4, 715, 8, 118, 1634, 14, 394, 20, 13, 119, 954, 189, 102, 5, 207, 110, 3103, 21, 14, 69, 188, 8, 30, 23, 7, 4, 249, 126, 93, 4, 114, 9, 2300, 1523, 5, 647, 4, 116, 9, 35, 8163, 4, 229, 9, 340, 1322, 4, 118, 9, 4, 130, 4901, 19, 4, 1002, 5, 89, 29, 952, 46, 37, 4, 455, 9, 45, 43, 38, 1543, 1905, 398, 4, 1649, 26, 6853, 5, 163, 11, 3215, 2, 4, 1153, 9, 194, 775, 7, 8255, 2, 349, 2637, 148, 605, 2, 8003, 15, 123, 125, 68, 2, 6853, 15, 349, 165, 4362, 98, 5, 4, 228, 9, 43, 2, 1157, 15, 299, 120, 5, 120, 174, 11, 220, 175, 136, 50, 9, 4373, 228, 8255, 5, 2, 656, 245, 2350, 5, 4, 9837, 131, 152, 491, 18, 2, 32, 7464, 1212, 14, 9, 6, 371, 78, 22, 625, 64, 1382, 9, 8, 168, 145, 23, 4, 1690, 15, 16, 4, 1355, 5, 28, 6, 52, 154, 462, 33, 89, 78, 285, 16, 145, 95]),\n",
       "       list([1, 14, 47, 8, 30, 31, 7, 4, 249, 108, 7, 4, 5974, 54, 61, 369, 13, 71, 149, 14, 22, 112, 4, 2401, 311, 12, 16, 3711, 33, 75, 43, 1829, 296, 4, 86, 320, 35, 534, 19, 263, 4821, 1301, 4, 1873, 33, 89, 78, 12, 66, 16, 4, 360, 7, 4, 58, 316, 334, 11, 4, 1716, 43, 645, 662, 8, 257, 85, 1200, 42, 1228, 2578, 83, 68, 3912, 15, 36, 165, 1539, 278, 36, 69, 2, 780, 8, 106, 14, 6905, 1338, 18, 6, 22, 12, 215, 28, 610, 40, 6, 87, 326, 23, 2300, 21, 23, 22, 12, 272, 40, 57, 31, 11, 4, 22, 47, 6, 2307, 51, 9, 170, 23, 595, 116, 595, 1352, 13, 191, 79, 638, 89, 2, 14, 9, 8, 106, 607, 624, 35, 534, 6, 227, 7, 129, 113]),\n",
       "       ...,\n",
       "       list([1, 11, 6, 230, 245, 6401, 9, 6, 1225, 446, 2, 45, 2174, 84, 8322, 4007, 21, 4, 912, 84, 2, 325, 725, 134, 2, 1715, 84, 5, 36, 28, 57, 1099, 21, 8, 140, 8, 703, 5, 2, 84, 56, 18, 1644, 14, 9, 31, 7, 4, 9406, 1209, 2295, 2, 1008, 18, 6, 20, 207, 110, 563, 12, 8, 2901, 2, 8, 97, 6, 20, 53, 4767, 74, 4, 460, 364, 1273, 29, 270, 11, 960, 108, 45, 40, 29, 2961, 395, 11, 6, 4065, 500, 7, 2, 89, 364, 70, 29, 140, 4, 64, 4780, 11, 4, 2678, 26, 178, 4, 529, 443, 2, 5, 27, 710, 117, 2, 8123, 165, 47, 84, 37, 131, 818, 14, 595, 10, 10, 61, 1242, 1209, 10, 10, 288, 2260, 1702, 34, 2901, 2, 4, 65, 496, 4, 231, 7, 790, 5, 6, 320, 234, 2766, 234, 1119, 1574, 7, 496, 4, 139, 929, 2901, 2, 7750, 5, 4241, 18, 4, 8497, 2, 250, 11, 1818, 7561, 4, 4217, 5408, 747, 1115, 372, 1890, 1006, 541, 9303, 7, 4, 59, 2, 4, 3586, 2]),\n",
       "       list([1, 1446, 7079, 69, 72, 3305, 13, 610, 930, 8, 12, 582, 23, 5, 16, 484, 685, 54, 349, 11, 4120, 2959, 45, 58, 1466, 13, 197, 12, 16, 43, 23, 2, 5, 62, 30, 145, 402, 11, 4131, 51, 575, 32, 61, 369, 71, 66, 770, 12, 1054, 75, 100, 2198, 8, 4, 105, 37, 69, 147, 712, 75, 3543, 44, 257, 390, 5, 69, 263, 514, 105, 50, 286, 1814, 23, 4, 123, 13, 161, 40, 5, 421, 4, 116, 16, 897, 13, 2, 40, 319, 5872, 112, 6700, 11, 4803, 121, 25, 70, 3468, 4, 719, 3798, 13, 18, 31, 62, 40, 8, 7200, 4, 2, 7, 14, 123, 5, 942, 25, 8, 721, 12, 145, 5, 202, 12, 160, 580, 202, 12, 6, 52, 58, 2, 92, 401, 728, 12, 39, 14, 251, 8, 15, 251, 5, 2, 12, 38, 84, 80, 124, 12, 9, 23]),\n",
       "       list([1, 17, 6, 194, 337, 7, 4, 204, 22, 45, 254, 8, 106, 14, 123, 4, 2, 270, 2, 5, 2, 2, 732, 2098, 101, 405, 39, 14, 1034, 4, 1310, 9, 115, 50, 305, 12, 47, 4, 168, 5, 235, 7, 38, 111, 699, 102, 7, 4, 4039, 9245, 9, 24, 6, 78, 1099, 17, 2345, 2, 21, 27, 9685, 6139, 5, 2, 1603, 92, 1183, 4, 1310, 7, 4, 204, 42, 97, 90, 35, 221, 109, 29, 127, 27, 118, 8, 97, 12, 157, 21, 6789, 2, 9, 6, 66, 78, 1099, 4, 631, 1191, 5, 2642, 272, 191, 1070, 6, 7585, 8, 2197, 2, 2, 544, 5, 383, 1271, 848, 1468, 2, 497, 2, 8, 1597, 8778, 2, 21, 60, 27, 239, 9, 43, 8368, 209, 405, 10, 10, 12, 764, 40, 4, 248, 20, 12, 16, 5, 174, 1791, 72, 7, 51, 6, 1739, 22, 4, 204, 131, 9])],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9999"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(seq) for seq in train_data])\n",
    "# 出現頻度の高い10,000個の単語に制限しているため、単語のインデックスが10,000を超えることはない"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "? this film was just brilliant casting location scenery story direction everyone's really suited the part they played and you could just imagine being there robert ? is an amazing actor and now the same being director ? father came from the same scottish island as myself so i loved the fact there was a real connection with this film the witty remarks throughout the film were great it was just brilliant so much that i bought the film as soon as it was released for ? and would recommend it to everyone to watch and the fly fishing was amazing really cried at the end it was so sad and you know what they say if you cry at a film it must have been good and this definitely was also ? to the two little boy's that played the ? of norman and paul they were just brilliant children are often left out of the ? list i think because the stars that play them all grown up are such a big profile for the whole film but these children are amazing and should be praised for what they have done don't you think the whole story was so lovely because it was true and was someone's life after all that was shared with us all\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "# IMDbのデータは整数インデックスで構成されている\n",
    "# 整数インデックスを英単語に戻すにはword_indexを使う\n",
    "word_index = imdb.get_word_index()\n",
    "reverse_word_index = dict( # 単語マッピング\n",
    "    [(value, key) for (key, value) in word_index.items()]\n",
    ")\n",
    "# 整数インデックスで構成されたデータを英単語に戻す関数\n",
    "def decode_review(data):\n",
    "    # レビューの0, 1, 2番目のインデックスは「パディング」「シーケンス開始」「不明」に予約されている\n",
    "    return ' '.join([reverse_word_index.get(i-3, '?') for i in data])\n",
    "\n",
    "print(decode_review(train_data[0])) # 訓練データ[0]のレビュー\n",
    "print(train_labels[0]) # 訓練データ[0]のラベル（0＝否定的、1＝肯定的）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## データの準備\n",
    "\n",
    "ニューラルネットワークに供給するためには、データをテンソル（n次元配列）に変換しなければならない\n",
    "\n",
    "これには次の2つの方法がある\n",
    "\n",
    "1. リストを全て同じ長さに揃え、形状が (samples, word_indicies) の整数型テンソルに変換する。さらに、ネットワークの最初の層を、そのようなテンソルを扱える層（埋め込み層）として使用する。\n",
    "2. one-hotエンコーディングによりリストを0と1のベクトルに変換する。たとえばシーケンス\\[3, 5\\]は、3、5番目のインデックスが1である以外は全て0の10,000次元のベクトルに変換される（単語数を10,000に限定しているため）。この場合、ネットワークの最初の層は、浮動小数点数のベクトルデータを扱うことができるDense層（全結合層）として使用する。\n",
    "\n",
    "今回は2番めの方法を採用する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 1., 1., ..., 0., 0., 0.])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def vectorize_sequence(sequences, dimension=10000):\n",
    "    res = np.zeros((len(sequences), dimension))\n",
    "    for i, seq in enumerate(sequences):\n",
    "        res[i, seq] = 1.\n",
    "    return res\n",
    "\n",
    "# 訓練データのベクトル化\n",
    "x_train = vectorize_sequence(train_data)\n",
    "# テストデータのベクトル化\n",
    "x_test = vectorize_sequence(test_data)\n",
    "\n",
    "x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10000"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ラベルもベクトル化\n",
    "y_train = np.asarray(train_labels).astype('float32')\n",
    "y_test = np.asarray(test_labels).astype('float32')\n",
    "\n",
    "y_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの構築\n",
    "\n",
    "　入力データがベクトルで、ラベルがスカラー（0と1）であるような単純な問題に適しているのは、単純な全結合層のスタックとReLU（Rectified Linear Unit）活性化関数で構成されたニューラルネットワークである\n",
    "\n",
    "**Dense(16, activation='relu')**\n",
    "\n",
    "　各Dense層に渡される引数(16)は、その層の隠れユニットの数である。ReLU活性化関数を持つDense層は、以下のテンソル演算の連鎖を実装する。\n",
    "\n",
    "**output = relu(dot(W, input) + b)**\n",
    "\n",
    "　16個の隠れユニットを持つということは、重み行列Wの形状が (input_dimension, 16) になるということ。通常、隠れユニットの数が多いほど複雑な学習が可能だが、計算量が増えるため無駄なパターンの学習が起こる可能性も増える。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "　今回は、以下のようなネットワークを採用する\n",
    "\n",
    "**input（ベクトル化されたレビュー） -> Dense(16) -> Dense(16) -> Dense(1) -> output（確率）**\n",
    "\n",
    "　今回の問題は二値分類問題であり、出力が確率となるため、ネットワークの最後の層はシグモイド活性関数を使用する単一ユニットとする"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 損失関数とオプティマイザを選択\n",
    "# 二値分類問題の場合、損失関数はbinary_crossentropyが最適\n",
    "# オプティマイザは今回、rmspropを採用\n",
    "# 指標は正解率（accuracy）を見ることとした\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15000, 10000)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 検証データセットの設定\n",
    "# 全く新しいデータセットでモデル訓練するときの正解率を監視するには、検証用のデータが必要\n",
    "# 検証用に訓練データをさらに10,000個のサンプルに切り分ける\n",
    "x_val, partial_x_train = x_train[:10000], x_train[10000:]\n",
    "y_val, partial_y_train = y_train[:10000], y_train[10000:]\n",
    "\n",
    "partial_x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/20\n",
      "15000/15000 [==============================] - 5s 314us/step - loss: 0.5223 - acc: 0.7747 - val_loss: 0.3959 - val_acc: 0.8592\n",
      "Epoch 2/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.3142 - acc: 0.9003 - val_loss: 0.3118 - val_acc: 0.8844\n",
      "Epoch 3/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.2307 - acc: 0.9255 - val_loss: 0.3005 - val_acc: 0.8809\n",
      "Epoch 4/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.1817 - acc: 0.9428 - val_loss: 0.2791 - val_acc: 0.8877\n",
      "Epoch 5/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.1481 - acc: 0.9544 - val_loss: 0.2772 - val_acc: 0.8876\n",
      "Epoch 6/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.1212 - acc: 0.9635 - val_loss: 0.3080 - val_acc: 0.8804\n",
      "Epoch 7/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0991 - acc: 0.9727 - val_loss: 0.3032 - val_acc: 0.8844\n",
      "Epoch 8/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.0817 - acc: 0.9773 - val_loss: 0.3296 - val_acc: 0.8790\n",
      "Epoch 9/20\n",
      "15000/15000 [==============================] - 1s 97us/step - loss: 0.0660 - acc: 0.9823 - val_loss: 0.3471 - val_acc: 0.8771\n",
      "Epoch 10/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0530 - acc: 0.9877 - val_loss: 0.3684 - val_acc: 0.8784\n",
      "Epoch 11/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0443 - acc: 0.9899 - val_loss: 0.3928 - val_acc: 0.8752\n",
      "Epoch 12/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.0324 - acc: 0.9939 - val_loss: 0.4527 - val_acc: 0.8660\n",
      "Epoch 13/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0273 - acc: 0.9944 - val_loss: 0.4544 - val_acc: 0.8771\n",
      "Epoch 14/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.0211 - acc: 0.9966 - val_loss: 0.4868 - val_acc: 0.8713\n",
      "Epoch 15/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.0177 - acc: 0.9966 - val_loss: 0.5187 - val_acc: 0.8690\n",
      "Epoch 16/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0096 - acc: 0.9993 - val_loss: 0.5492 - val_acc: 0.8711\n",
      "Epoch 17/20\n",
      "15000/15000 [==============================] - 1s 91us/step - loss: 0.0113 - acc: 0.9984 - val_loss: 0.5870 - val_acc: 0.8660\n",
      "Epoch 18/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0085 - acc: 0.9989 - val_loss: 0.6025 - val_acc: 0.8698\n",
      "Epoch 19/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.6361 - val_acc: 0.8696\n",
      "Epoch 20/20\n",
      "15000/15000 [==============================] - 1s 92us/step - loss: 0.0065 - acc: 0.9984 - val_loss: 0.6650 - val_acc: 0.8679\n"
     ]
    }
   ],
   "source": [
    "# モデルの訓練\n",
    "# 512サンプルのミニバッチで20エポックの訓練を行う\n",
    "history = model.fit(partial_x_train, partial_y_train, epochs=20, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['val_loss', 'val_acc', 'loss', 'acc'])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 訓練中に起こったイベントの内容を確認\n",
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 訓練データと検証データの損失値をプロット\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "history_dict = history.history\n",
    "loss_values = history_dict['loss']\n",
    "val_loss_values = history_dict['val_loss']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.plot(epochs, loss_values, 'bo', label='Training loss') # \"bo\"は\"blue dot\"（青の点線）のこと\n",
    "plt.plot(epochs, val_loss_values, 'b', label='Validation loss') # \"b\"は\"solid blue line\"（青の実線）のこと\n",
    "plt.title(\"Training and validation loss\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYsAAAEWCAYAAACXGLsWAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMi4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvhp/UCwAAIABJREFUeJzt3Xl8VPW9//HXhx1kJ7iBELS2KsgSYtxwqVpFRahLq0hvVVSqFZfe+rv1qrdaFe21rdfaer3iWjWV2lqtuOBCUdwlKATFKggRI4gREMGAEPj8/viewGTIZIbMlpD38/E4jzn7fOZkcj7z/X7P+R5zd0RERBrSKt8BiIhI06dkISIiSSlZiIhIUkoWIiKSlJKFiIgkpWQhIiJJKVlIysystZmtNbN+mVw3n8zsW2aW8evHzewYM6uImf7AzA5LZd1GvNfdZnZlY7cXSUWbfAcg2WNma2MmOwHfAJui6Z+4e+n27M/dNwGdM71uS+Du38nEfszsPOBH7n5kzL7Py8S+RRqiZLEDc/ctJ+vol+t57v5CovXNrI271+QiNpFk9H1sWlQN1YKZ2Q1m9hcze9jM1gA/MrODzewNM/vSzJaZ2W1m1jZav42ZuZkVRtMPRcufMbM1Zva6mQ3Y3nWj5ceb2YdmttrM/mBmr5rZ2QniTiXGn5jZQjNbZWa3xWzb2sz+x8xWmNlHwMgGjs/VZjYlbt7tZnZLNH6emb0ffZ6Pol/9ifZVaWZHRuOdzOzBKLb3gOH1vO+iaL/vmdnoaP7+wB+Bw6Iqvi9iju21MdtfEH32FWb2uJntlsqx2Z7jXBuPmb1gZivN7DMz+4+Y9/mv6Jh8ZWZlZrZ7fVV+ZvZK7d85Op4zo/dZCVxtZnub2Yzos3wRHbduMdv3jz5jVbT892bWIYp535j1djOzajPrlejzShLurqEFDEAFcEzcvBuADcBJhB8OHYEDgAMJpc49gQ+BidH6bQAHCqPph4AvgGKgLfAX4KFGrLszsAYYEy37d2AjcHaCz5JKjP8AugGFwMrazw5MBN4D+gK9gJnh36De99kTWAvsFLPvz4HiaPqkaB0DjgLWAYOjZccAFTH7qgSOjMZ/C7wI9AD6A/Pj1v0hsFv0NzkzimGXaNl5wItxcT4EXBuNHxvFOBToAPwv8M9Ujs12HuduwHLgUqA90BUoiZb9JzAX2Dv6DEOBnsC34o818Ert3zn6bDXAhUBrwvfx28DRQLvoe/Iq8NuYz/NudDx3itY/NFo2GZgU8z4/Bx7L9/9hcx7yHoCGHP2hEyeLfybZ7nLgr9F4fQng/2LWHQ2824h1xwMvxywzYBkJkkWKMR4Us/zvwOXR+ExCdVztshPiT2Bx+34DODMaPx74sIF1nwQuisYbShZLYv8WwE9j161nv+8CJ0bjyZLFn4AbY5Z1JbRT9U12bLbzOP8bUJZgvY9q442bn0qyWJQkhtOAWdH4YcBnQOt61jsUWAxYND0HOCXT/1ctaVA1lHwSO2Fm+5jZU1G1wlfAdUBBA9t/FjNeTcON2onW3T02Dg//3ZWJdpJijCm9F/BxA/EC/BkYG42fCWy5KMDMRpnZm1E1zJeEX/UNHatauzUUg5mdbWZzo6qUL4F9UtwvhM+3ZX/u/hWwCugTs05Kf7Mkx3kPYGGCGPYgJIzGiP8+7mpmj5jZp1EM98fFUOHhYoo63P1VQillhJkNAvoBTzUyJkFtFhJ+aca6k/BL9lvu3hX4JeGXfjYtI/zyBcDMjLont3jpxLiMcJKplezS3r8Ax5hZX0I12Z+jGDsCfwNuIlQRdQeeSzGOzxLFYGZ7AncQqmJ6Rfv9V8x+k13mu5RQtVW7vy6E6q5PU4grXkPH+RNgrwTbJVr2dRRTp5h5u8atE//5/ptwFd/+UQxnx8XQ38xaJ4jjAeBHhFLQI+7+TYL1JAVKFhKvC7Aa+DpqIPxJDt7zSaDIzE4yszaEevDeWYrxEeAyM+sTNXb+oqGV3X05oarkPuADd18QLWpPqEevAjaZ2ShC3XqqMVxpZt0t3IcyMWZZZ8IJs4qQN88jlCxqLQf6xjY0x3kYONfMBptZe0Iye9ndE5bUGtDQcX4C6GdmE82snZl1NbOSaNndwA1mtpcFQ82sJyFJfka4kKK1mU0gJrE1EMPXwGoz24NQFVbrdWAFcKOFiwY6mtmhMcsfJFRbnUlIHJIGJQuJ93PgLEKD852EX9ZZFZ2QTwduIfzz7wW8Q/hFmekY7wCmA/OAWYTSQTJ/JrRB/Dkm5i+BnwGPERqJTyMkvVRcQyjhVADPEHMic/dy4DbgrWidfYA3Y7Z9HlgALDez2Oqk2u2nEaqLHou27weMSzGueAmPs7uvBr4HnEpoUP8QOCJa/BvgccJx/orQ2Nwhql48H7iScLHDt+I+W32uAUoISesJ4NGYGGqAUcC+hFLGEsLfoXZ5BeHvvMHdX9vOzy5xaht/RJqMqFphKXCau7+c73ik+TKzBwiN5tfmO5bmTjflSZNgZiMJ1QrrCZde1hB+XYs0StT+MwbYP9+x7AhUDSVNxQhgEaF6YiTwfTVISmOZ2U2Eez1udPcl+Y5nR6BqKBERSUolCxERSWqHabMoKCjwwsLCfIchItKszJ49+wt3b+hSdWAHShaFhYWUlZXlOwwRkWbFzJL1YgCoGkpERFKgZCEiIkkpWYiISFJKFiIikpSShYiIJJW1ZGFm95rZ52b2boLlFj0+caGZlZtZUcyys8xsQTScla0YRUTyqrQUCguhVavwWlqabIu8yWbJ4n4aeL4x4alje0fDBEJvoERdGV9DeJxjCXCNmfXIYpwi0lzl+2SbzvuXlsKECfDxx+AeXidMaLIJI2vJwt1nErpuTmQM8IAHbwDdLTxY/jjgeXdf6e6rCF0yN5R0RKQlysTJNp8n+6uugurquvOqq8P87YkhR8kyn20Wfaj7CMXKaF6i+dswswlmVmZmZVVVVVkLVEQSSPdklc726Z5s832yX5Kgf8NE8+PluGSSz2RR3+MnvYH52850n+zuxe5e3Lt30rvVRSST0j1Zpbt9uifbfJ/s+yV4om+i+fEyUTLZDvlMFpXUfQ5xX8IDbxLNF5F4zfmXfbrbp3uyzffJftIk6NSp7rxOncL8VKQb//Zy96wNQCHwboJlJxIeKWnAQcBb0fyewGLCQ+Z7ROM9k73X8OHDXaRFeegh906d3MPv8jB06hTm52J7s7rb1g5mudk+3fj796///fv3z8371+6jf//wmfv3375t040/ApR5KufzVFZqzEB4cPwyYCOhtHAucAFwQbTcgNuBjwjPyS2O2XY8sDAazknl/ZQspMVJ92TR3Ld3T+9km++TfboyEb83gWSR60HJQlqc5v7LPkMnu7Tk82SfCRmIX8lCpDnIZzVEvn/ZZ2J7SVuqyWKHeaxqcXGx63kW0qzUXg0U28jbqRNMngzjxjX97WWHYGaz3b042XrqG0okHfm8mmjcuHBi798fzMLr9pzo091eWhSVLEQaK91f5q1ahYqfeGaweXPm4hRpgEoWItmW7/sERHJIyUKksdK9KSrdm7JEckjJQqSx0i0ZqM1AmhElC2nZ0mmgzkTJYNw4qKgIbRQVFUoU0mQpWUjLlW5HdioZSAuiq6Gk5SosDAkiXv/+4Ve+SAugq6FEksl1r50izZiShTRv6bQ56NJVkZQpWUjzlW6bgy5dFUmZkoU0X/nuLkOkBVEDtzRf6i5DJG1q4JbmQW0OIs2CkoXkj9ocRJoNJQvJH7U5iDQbarOQ/FGbg0jeqc1Cmj61OYg0G0oWkj9qcxBpNpQsJH/U5iDSbLTJdwDSwo0bp+Qg0gyoZCHpSec+CRFpNlSykMarvU+i9vLX2vskQKUFkR2MShbSeOneJyEizYaShTSengch0mIoWUjj6T4JkRZDyUIaT/dJiLQYShbSeLpPQqTF0NVQkh7dJyHSIqhk0dLpPgkRSYFKFi2Z7pMQkRSpZNGS6T4JEUmRkkVLpvskRCRFWU0WZjbSzD4ws4VmdkU9y/ub2XQzKzezF82sb8yyTWY2JxqeyGacLZbukxCRFGUtWZhZa+B24HhgP2Csme0Xt9pvgQfcfTBwHXBTzLJ17j40GkZnK84WTfdJiEiKslmyKAEWuvsid98ATAHGxK2zHzA9Gp9Rz3LJJt0nISIpymay6AN8EjNdGc2LNRc4NRo/GehiZr2i6Q5mVmZmb5jZ9+t7AzObEK1TVlVVlcnYW45x46CiIjzzuqJCiUJE6pXNZGH1zPO46cuBI8zsHeAI4FOgJlrWL3qI+JnArWa21zY7c5/s7sXuXty7d+8Mhi4iIrGyeZ9FJbBHzHRfYGnsCu6+FDgFwMw6A6e6++qYZbj7IjN7ERgGfJTFeEVEJIFslixmAXub2QAzawecAdS5qsnMCsysNob/BO6N5vcws/a16wCHAvOzGGvzpTuwRSQHslaycPcaM5sIPAu0Bu519/fM7DqgzN2fAI4EbjIzB2YCF0Wb7wvcaWabCQnt1+6uZBFPd2CLSI6Ye3wzQvNUXFzsZWVl+Q4jtwoLQ4KI179/aKwWEUnCzGZH7cMN0h3czZnuwBaRHFGyaM50B7aI5IiSRXOmO7BFJEeULJoz3YEtIjmi51k0d3pSnYjkgEoWIiKSlJKFiIgkpWQhIiJJKVmIiEhSShYiIpKUkoWIiCSlZCEiIkkpWYiISFJKFvmm51GISDOgO7jzSc+jEJFmQiWLfLrqqq2JolZ1dZgvItKEKFnkk55HISLNhJJFPul5FCLSTChZ5JOeRyEizYSSRT7peRQi0kzoaqh80/MoRKQZUMlCRESSUrIQEZGklCxERCQpJQsREUlKyUJERJJSshARkaSULEREJCklCxERSSppsjCziWbWIxfBiIhI05RKyWJXYJaZPWJmI83Msh2UiIg0LUmThbtfDewN3AOcDSwwsxvNbK8sxyYiIk1ESm0W7u7AZ9FQA/QA/mZmN2cxNhERaSKSdiRoZpcAZwFfAHcD/8/dN5pZK2AB8B/ZDVFERPItlV5nC4BT3P3j2JnuvtnMRmUnLBERaUpSqYZ6GlhZO2FmXczsQAB3f7+hDaMG8Q/MbKGZXVHP8v5mNt3Mys3sRTPrG7PsLDNbEA1npf6Rcqy0FAoLoVWr8Fpamu+IREQyLpVkcQewNmb662heg8ysNXA7cDywHzDWzPaLW+23wAPuPhi4Drgp2rYncA1wIFACXNMkL98tLYUJE+Djj8E9vE6YoIQhIjucVJKFRQ3cQKh+IrXqqxJgobsvcvcNwBRgTNw6+wHTo/EZMcuPA55395Xuvgp4HhiZwnvm1lVXQXV13XnV1WG+iMgOJJVkscjMLjGzttFwKbAohe36AJ/ETFdG82LNBU6Nxk8GuphZrxS3xcwmmFmZmZVVVVWlEFKGLVmyffNFRJqpVJLFBcAhwKeEk/aBwIQUtqvv5j2Pm74cOMLM3gGOiN6jJsVtcffJ7l7s7sW9e/dOIaQM69dv++aLiDRTqdyU97m7n+HuO7v7Lu5+prt/nsK+K4E9Yqb7Akvj9r3U3U9x92HAVdG81als2yRMmgSdOtWd16lTmC8isgNJ5T6LDsC5wECgQ+18dx+fZNNZwN5mNoBQYjgDODNu3wXAyqgd5D+Be6NFzwI3xjRqHxstb1rGjQuvV10Vqp769QuJona+iMgOIpVqqAcJ/UMdB7xE+JW/JtlG7l4DTCSc+N8HHnH398zsOjMbHa12JPCBmX0I7AJMirZdCVxPSDizgOuieU3PuHFQUQGbN4dXJQoR2QFZzIVO9a9g9o67DzOzcncfbGZtgWfd/ajchJia4uJiLysry3cYIiLNipnNdvfiZOulUrLYGL1+aWaDgG5AYRqxiYhIM5PK/RKTo7aDq4EngM7Af2U1KhERaVIaTBZRZ4FfRTfGzQT2zElUIiLSpDRYDRVdpTQxR7FIY23eDBs3wqZNYTxJO5SIyPZKpc3ieTO73Mz2MLOetUPWI5OGbd4ML70E48dD9+7Qrh20aQOtW4dODc3Ca+vW0LZtWN6hA3TsGO4F6dwZunSBrl2hRw8YPRqmToWamnx/MhFpglJps6i9n+KimHmOqqTyY9EieOCBMCxeHE76P/gB7LlnKFG4by1d1L4mm1ddDf/4R0gWu+8eEtC554ZedEVESOHS2eYir5fOrl4NO+0Uftlnw5o18Ne/wp/+BDNnhlLD0UfDWWfBySeH907Xxo3w5JNw110wbVqY973vwfnnh1JHu3bpv0ciq1aFUk62jp+IJJTqpbOp3Gfx4/rmu/sDjYwtK/KWLObOhYMPDr/S998fhg3bOgwevG13IKnatAlmzAgJ4u9/D7/+v/3tkCD+7d9gjz2S76OxliyBe++Fe+6Bykro3RvOPhvOOy/EkI4NG6C8HF5/Hd54IwyLFoWqtOOPhxNPhJEjoVevjHwUEWlYJpPFH2ImOwBHA2+7+2nphZhZeUkW1dUwfDh8+WW4c/udd8KwalVY3qoV7LNP3QQybFhoI0jkww9DgnjwQfjkE+jWDc44IySJgw4KpYpc2bQJnn02lDamTg3TRxwRShunnhraQJKprNyaFN54A2bPhvXrw7Lddw+JdvhwWLAAnnoKPv88HLdDDoFRo0LyGDgwt59bpAXJWLKoZ8fdgAfdfXTSlXMoL8niJz8JJ9LnnoNjjgnz3MMv89rE8fbb4fXTT7du179/3eSxzz7wz3+GJPH66+FkedxxIUGMHh0apfNt2TK4/364++5QEujRI5Rwzj8fBg0K66xbF5JBbHKo/dzt24ekcNBBIUEcdBD07Vv3PTZvhrKyUB321FPh2EE4XqNGheHII1NLUiKSkmwmi7ZAubvv29jgsiHnyeJvfwsNy7/4Bfz618nXr6ramkBqhwUL6l7mut9+obpn3Ljwq7sp2rw5VI/ddVeoHtu4EUpKwvw5c7ZeTTVgwNakcNBBMGTI9rd7fPopPP10SB4vvBBKcp06hcRcW+poqsdJpJnIZDXUVLY+S6IV4el2j7j7Ns/UzqecJoslS8LJb++94dVXw6WpjbFmTWjzmD8fiorCL+/mVN3yxRfhqqzS0lBdVpsYDjwQdtkls++1fj28+GJIHE8+GR5hC+G4nXhiKKHtvjv06QO77qrGcpEUZTJZHBEzWQN87O6VacaXcTlLFjU1cNRRoWQwZw7stVf231Pqcof33gtVVU8+Ca+9Fko2tcxCsurTJwy1SSR+vHv3+pOze0jkK1duHVasaHi6d+9wgUPtMHBgSKAiTVyqySKVn19LgGXuvj7acUczK3T3ijRjbJ4mTYKXXw4N0EoU+WEW2kkGDQrVgF9+GdpRli4NVVeffrp1vKIilP5WrNh2Px07huSx++6h8T725N/QzYk77QQ9e4ahVy/Yd1/47LNQyloT03t/v351E8j++8N3vpPdy5C314oVoRq1pga+/30YMSLcyCkSJ5WSRRlwiLtviKbbAa+6+wE5iC9lOSlZvPJKuBrozDNDspDmY/360Egfn0xqx9u0qZsAasfrm27fvv73qL24Yd68usO//rU1+bRpEy5o2H//kOxqk0j//rmtgty8Ge67b2uybdMGvvkmlJBGj4ZTTgn38iT6rLLDyGQ11Bx3Hxo3b667D0kzxozKerJYtQqGDg3/VO+8E7rJEEnFhg3hkuj4JFLb7gLhu3XtteFEne2kMWcO/PSn4cq7ESPgf/833K0/bVq4aOGpp0IJqUuX0B508snhHpguXbIbl+RFqskCd29wAJ4HRsdMjwGmJ9su18Pw4cM9azZvdj/tNPc2bdzffDN77yMty+rV7q++6n7bbe577x06YSkqcn/iifCdy8b7XXqpe6tW7r17u99/f/3vs369+1NPuZ93XlgP3Nu3dx81yv2ee9yrqjIfm+QNUOYpnGNTSRZ7AW8Q2i6WAK8B30pl57kcspos7rorHKpf/zp77yEt28aN4eS9117hu1Zc7P7kk5lJGps3uz/8sPtuu7mbuV94ofvKlaltW1PjPnOm+2WXuffvH2Jr1cr9yCPdf/979yVL0o9P8irVZJHyfRZm1plQbZX0+dv5kLVqqPffh+LicM/Ac8+FG+ZEsmXjRnjoIbj++tBRZElJqJ4aObJx1VP/+hdcdFG46XP4cLjjDjigkc2N7qEK9rHHwvDee2F+cTEcdlioyiosDPfYFBZmt9pq9erQw0HtUFAQrlLs3j1777mDymSbxY3Aze7+ZTTdA/i5u1+dkUgzJCvJYv36cN/Ap5+G+yF0A5jkysaN4eqq668PbRsHHRSSxrHHppY0qqvDlXu/+U24kfGmm2DChMxe6fThhyFpPP546O+rurru8p496yaP+KFz5/r3+803oZuYTz4JFwzU9/rVV9tu17p1OE4jR4YeEIYPz/6Pu3XrwrmhqmrrIwFih1Tnde4cEl4erkTLZLJ4x92Hxc17292L0owxo7KSLC67DH7/+9Av0qhRmd23SCo2bAjdrEyaFE6UhxwSksYxxyROGlOnwsUXhyTz4x/DzTdn/ibJeO7hJs2KijAsXrx1vHZYt67uNgUFWxPH5s1bE8Hy5dvuv6AgXIq8xx7bvu6xR/is06aFvsxqzwMFBSG5HndceN111/Q+Y01NuIF21ix4663wOm9e5p4B06oV7LxziLN22GWXutO1Q7duGbsQIpPJohw4wN2/iaY7Euq4BmYk0gzJeLJ4+ulwJcjFF8Ntt2VuvyKNsWFD6Al40qTwq3vECPjVr+C739160qiogEsuCcliv/3CVU5HHNHgbnPGPXQSWV8yWbw4nCgTJYO+fbev9+aqKnj++a3J4/PPw/yhQ7eWOg45pOH7XdzDvTu1SWHWrNBXWW3pqXv3UP1WUhKq9fr2DQlv06atT6ysHY8dEs1fsybcqxM7LF8eXjdu3Da+9u3rJpNhw8KPiEbIZLL4D2A0cF806xzgCXe/uVGRZUlGk8WyZaE7j912gzffVMd10nR8803oOv7GG0P16OGHwy9/Gb6nN9wQTrrXXguXXtr4bmh2JJs3h2qiZ58NyePVV0NJoHPn0MZRmzw6dtyaFN56K5ROVq4M++jQIXQrc8ABYSgpCTfk5qL90j1ctl9fEokdvvUtePTRRr1FRjsSNLORwDGAAauA3dz9ooa3yq2MJYvNm8OX59VXQw+q+zap/hJFgvXrQw/AN90UbiqE0G38//xPdp910tx99VXoCHPatDBUVNRd3rp1uFmyNikccEDoumUHTryZ7O4D4DNgM/BDYDHQuBTWHPzud6GH0zvvVKKQpqtDB5g4MTyQasqUkCCOPjrfUTV9XbvCmDFhcA89Pz/3XChtHHBAqM5p7APLdnAJSxZm9m3gDGAssAL4C3C5u/fPXXipy0jJYtasUJc5Zkx4jGlz6gFWRKQRMlGy+BfwMnCSuy+MdvqzDMXX9KxZA2PHhnaKu+5SohARidFQsjiVULKYYWbTgCmENosd08SJ4aqMF19s+LGnIiItUMLmfHd/zN1PB/YBXgR+BuxiZneY2bE5ii83SkvDDVD/9V/hTlQREakj6bVf7v61u5e6+yigLzAHaFJPyUvL4sVw4YVw6KFwdZO6KV1EpMnYrguF3X2lu9/p7kdlK6Cc23330F1zaakexSkikoDOju3bhyeFiYhIQupCVUREklKyEBGRpJQsREQkqawmCzMbaWYfmNlCM9vmCioz62dmM8zsHTMrN7MTovmFZrbOzOZEw/9lM04REWlY1hq4zaw1cDvwPaASmGVmT7j7/JjVrgYecfc7zGw/4GmgMFr2kbsPzVZ8IiKSumyWLEqAhe6+yN03EO4AHxO3jgNdo/FuwNIsxiMiIo2UzWTRB/gkZroymhfrWuBHZlZJKFVcHLNsQFQ99ZKZ1XtbtZlNMLMyMyurqqrKYOgiIhIrm8mivn6k4ru4HQvc7+59gROAB82sFbAM6Bc9zvXfgT+bWde4bXH3ye5e7O7FvXv3znD4IiJSK5vJohKIfQpLX7atZjoXeATA3V8HOgAF7v6Nu6+I5s8GPgK+ncVYRUSkAdlMFrOAvc1sgJm1I/Rg+0TcOkuAowHMbF9Csqgys95RAzlmtiewN7Aoi7GKiEgDsnY1lLvXmNlE4FmgNXCvu79nZtcBZe7+BPBz4K7oORkOnO3ubmaHA9eZWQ2wCbjA3VdmK1YREWlYSs/gbg4y9gxuEZEWJNUn5ekObhERSUrJQkREklKyEBGRpJQsREQkKSULERFJSslCRESSUrIQEZGklCxERCQpJQsREUlKyUJERJJSshARkaSULEREJCklCxERSUrJQkREklKyEBGRpJQsREQkKSULERFJSslCRESSUrIQEZGklCxERCQpJQsREUlKyUJERJJSshARkaSULEREJCklCxERSUrJQkREklKyEBGRpJQsREQkKSULERFJSslCRESSUrIQEZGklCxERCSpNvkOQESav40bN1JZWcn69evzHYok0KFDB/r27Uvbtm0btb2ShYikrbKyki5dulBYWIiZ5TsciePurFixgsrKSgYMGNCofagaSkTStn79enr16qVE0USZGb169Uqr5JfVZGFmI83sAzNbaGZX1LO8n5nNMLN3zKzczE6IWfaf0XYfmNlx2YxTRNKnRNG0pfv3yVo1lJm1Bm4HvgdUArPM7Al3nx+z2tXAI+5+h5ntBzwNFEbjZwADgd2BF8zs2+6+KVvxiohIYtksWZQAC919kbtvAKYAY+LWcaBrNN4NWBqNjwGmuPs37r4YWBjtT0R2BKWlUFgIrVqF19LStHa3YsUKhg4dytChQ9l1113p06fPlukNGzaktI9zzjmHDz74oMF1br/9dkrTjLW5ymYDdx/gk5jpSuDAuHWuBZ4zs4uBnYBjYrZ9I27bPvFvYGYTgAkA/fr1y0jQIpJlpaUwYQJUV4fpjz8O0wDjxjVql7169WLOnDkAXHvttXTu3JnLL7+8zjrujrvTqlX9v5Hvu+++pO9z0UUXNSq+HUE2Sxb1VZB53PRY4H537wucADxoZq1S3BZ3n+zuxe5e3Lt377QDFpEcuOqqrYmiVnV1mJ9hCxcuZNCgQVxwwQUUFRWxbNkyJkxpIPteAAAQBElEQVSYQHFxMQMHDuS6667bsu6IESOYM2cONTU1dO/enSuuuIIhQ4Zw8MEH8/nnnwNw9dVXc+utt25Z/4orrqCkpITvfOc7vPbaawB8/fXXnHrqqQwZMoSxY8dSXFy8JZHFuuaaazjggAO2xOceTnEffvghRx11FEOGDKGoqIiKigoAbrzxRvbff3+GDBnCVVk4VslkM1lUAnvETPdlazVTrXOBRwDc/XWgA1CQ4rYi0hwtWbJ989M0f/58zj33XN555x369OnDr3/9a8rKypg7dy7PP/888+fP32ab1atXc8QRRzB37lwOPvhg7r333nr37e689dZb/OY3v9mSeP7whz+w6667MnfuXK644greeeedere99NJLmTVrFvPmzWP16tVMmzYNgLFjx/Kzn/2MuXPn8tprr7HzzjszdepUnnnmGd566y3mzp3Lz3/+8wwdndRlM1nMAvY2swFm1o7QYP1E3DpLgKMBzGxfQrKoitY7w8zam9kAYG/grSzGKiK5kqjKOEtVyXvttRcHHHDAlumHH36YoqIiioqKeP/99+tNFh07duT4448HYPjw4Vt+3cc75ZRTtlnnlVde4YwzzgBgyJAhDBw4sN5tp0+fTklJCUOGDOGll17ivffeY9WqVXzxxRecdNJJQLiRrlOnTrzwwguMHz+ejh07AtCzZ8/tPxBpylqycPcaYCLwLPA+4aqn98zsOjMbHa32c+B8M5sLPAyc7cF7hBLHfGAacJGuhBLZQUyaBJ061Z3XqVOYnwU77bTTlvEFCxbw+9//nn/+85+Ul5czcuTIeu89aNeu3Zbx1q1bU1NTU+++27dvv806tdVJDamurmbixIk89thjlJeXM378+C1x1HeJq7vn/dLkrN5n4e5Pu/u33X0vd58Uzfuluz8Rjc9390PdfYi7D3X352K2nRRt9x13fyabcYpIDo0bB5MnQ//+YBZeJ09udOP29vjqq6/o0qULXbt2ZdmyZTz77LMZf48RI0bwyCOPADBv3rx6Sy7r1q2jVatWFBQUsGbNGh599FEAevToQUFBAVOnTgXCzY7V1dUce+yx3HPPPaxbtw6AlStXZjzuZNTdh4jk3rhxOUkO8YqKithvv/0YNGgQe+65J4ceemjG3+Piiy/mxz/+MYMHD6aoqIhBgwbRrVu3Ouv06tWLs846i0GDBtG/f38OPHDrhaKlpaX85Cc/4aqrrqJdu3Y8+uijjBo1irlz51JcXEzbtm056aSTuP766zMee0MslSJTc1BcXOxlZWX5DkOkRXr//ffZd9998x1Gk1BTU0NNTQ0dOnRgwYIFHHvssSxYsIA2bfL/27y+v5OZzXb34mTb5j96EZEdyNq1azn66KOpqanB3bnzzjubRKJIV/P/BCIiTUj37t2ZPXt2vsPIOPU6KyIiSSlZiIhIUkoWIiKSlJKFiIgkpWQhIs3ekUceuc0Ndrfeeis//elPG9yuc+fOACxdupTTTjst4b6TXZZ/6623Uh3TOeIJJ5zAl19+mUrozYaShYg0e2PHjmXKlCl15k2ZMoWxY8emtP3uu+/O3/72t0a/f3yyePrpp+nevXuj99cU6dJZEcmsyy6DerrkTsvQoRB1DV6f0047jauvvppvvvmG9u3bU1FRwdKlSxkxYgRr165lzJgxrFq1io0bN3LDDTcwZkzd57BVVFQwatQo3n33XdatW8c555zD/Pnz2Xfffbd0sQFw4YUXMmvWLNatW8dpp53Gr371K2677TaWLl3Kd7/7XQoKCpgxYwaFhYWUlZVRUFDALbfcsqXX2vPOO4/LLruMiooKjj/+eEaMGMFrr71Gnz59+Mc//rGlo8BaU6dO5YYbbmDDhg306tWL0tJSdtllF9auXcvFF19MWVkZZsY111zDqaeeyrRp07jyyivZtGkTBQUFTJ8+PWN/AiULEWn2evXqRUlJCdOmTWPMmDFMmTKF008/HTOjQ4cOPPbYY3Tt2pUvvviCgw46iNGjRyfsmO+OO+6gU6dOlJeXU15eTlFR0ZZlkyZNomfPnmzatImjjz6a8vJyLrnkEm655RZmzJhBQUFBnX3Nnj2b++67jzfffBN358ADD+SII46gR48eLFiwgIcffpi77rqLH/7whzz66KP86Ec/qrP9iBEjeOONNzAz7r77bm6++WZ+97vfcf3119OtWzfmzZsHwKpVq6iqquL8889n5syZDBgwIOP9RylZiEhmNVACyKbaqqjaZFH7a97dufLKK5k5cyatWrXi008/Zfny5ey666717mfmzJlccsklAAwePJjBgwdvWfbII48wefJkampqWLZsGfPnz6+zPN4rr7zCySefvKXn21NOOYWXX36Z0aNHM2DAAIYOHQok7ga9srKS008/nWXLlrFhwwYGDBgAwAsvvFCn2q1Hjx5MnTqVww8/fMs6me7GXG0WGX4WsIjkx/e//32mT5/O22+/zbp167aUCEpLS6mqqmL27NnMmTOHXXbZpd5uyWPVV+pYvHgxv/3tb5k+fTrl5eWceOKJSffTUN97td2bQ+Ju0C+++GImTpzIvHnzuPPOO7e8X31dlme7G/OWnSxqnwX88cfgvvVZwEoYIs1O586dOfLIIxk/fnydhu3Vq1ez884707ZtW2bMmMHHH3/c4H4OP/xwSqNzwLvvvkt5eTkQujffaaed6NatG8uXL+eZZ7Y+OaFLly6sWbOm3n09/vjjVFdX8/XXX/PYY49x2GGHpfyZVq9eTZ8+fQD405/+tGX+scceyx//+Mct06tWreLggw/mpZdeYvHixUDmuzFv2ckih88CFpHsGzt2LHPnzt3ypDqAcePGUVZWRnFxMaWlpeyzzz4N7uPCCy9k7dq1DB48mJtvvpmSkhIgPPVu2LBhDBw4kPHjx9fp3nzChAkcf/zxfPe7362zr6KiIs4++2xKSko48MADOe+88xg2bFjKn+faa6/lBz/4AYcddlid9pCrr76aVatWMWjQIIYMGcKMGTPo3bs3kydP5pRTTmHIkCGcfvrpKb9PKlp2F+WtWoUSRTwz2Lw5M4GJtADqorx5SKeL8pZdssjxs4BFRJqrlp0scvwsYBGR5qplJ4s8PgtYZEezo1Rp76jS/fvoPos8PQtYZEfSoUMHVqxYQa9evbJ6+aY0jruzYsUKOnTo0Oh9KFmISNr69u1LZWUlVVVV+Q5FEujQoQN9+/Zt9PZKFiKStrZt2265c1h2TC27zUJERFKiZCEiIkkpWYiISFI7zB3cZlYFNNzpS34VAF/kO4gGKL70KL70KL70pBNff3fvnWylHSZZNHVmVpbKLfX5ovjSo/jSo/jSk4v4VA0lIiJJKVmIiEhSSha5MznfASSh+NKj+NKj+NKT9fjUZiEiIkmpZCEiIkkpWYiISFJKFhliZnuY2Qwze9/M3jOzS+tZ50gzW21mc6Lhl3mIs8LM5kXvv82jBS24zcwWmlm5mRXlMLbvxBybOWb2lZldFrdOTo+hmd1rZp+b2bsx83qa2fNmtiB67ZFg27OidRaY2Vk5jO83Zvav6O/3mJl1T7Btg9+FLMZ3rZl9GvM3PCHBtiPN7IPou3hFDuP7S0xsFWY2J8G2uTh+9Z5X8vIddHcNGRiA3YCiaLwL8CGwX9w6RwJP5jnOCqCggeUnAM8ABhwEvJmnOFsDnxFuGMrbMQQOB4qAd2Pm3QxcEY1fAfx3Pdv1BBZFrz2i8R45iu9YoE00/t/1xZfKdyGL8V0LXJ7C3/8jYE+gHTA3/v8pW/HFLf8d8Ms8Hr96zyv5+A6qZJEh7r7M3d+OxtcA7wN98htVo4wBHvDgDaC7me2WhziOBj5y97zele/uM4GVcbPHAH+Kxv8EfL+eTY8Dnnf3le6+CngeGJmL+Nz9OXeviSbfABrfL3WaEhy/VJQAC919kbtvAKYQjntGNRSfhQdz/BB4ONPvm6oGzis5/w4qWWSBmRUCw4A361l8sJnNNbNnzGxgTgMLHHjOzGab2YR6lvcBPomZriQ/Se8MEv+T5vsY7uLuyyD8MwM717NOUzmO4wklxfok+y5k08SomuzeBFUoTeH4HQYsd/cFCZbn9PjFnVdy/h1UssgwM+sMPApc5u5fxS1+m1CtMgT4A/B4ruMDDnX3IuB44CIzOzxueX2POcvp9dVm1g4YDfy1nsVN4Rimoikcx6uAGqA0wSrJvgvZcgewFzAUWEao6omX9+MHjKXhUkXOjl+S80rCzeqZ1+hjqGSRQWbWlvAHLXX3v8cvd/ev3H1tNP400NbMCnIZo7svjV4/Bx4jFPdjVQJ7xEz3BZbmJrotjgfedvfl8QuawjEEltdWzUWvn9ezTl6PY9SYOQoY51EFdrwUvgtZ4e7L3X2Tu28G7krwvvk+fm2AU4C/JFonV8cvwXkl599BJYsMieo37wHed/dbEqyza7QeZlZCOP4rchjjTmbWpXac0BD6btxqTwA/jq6KOghYXVvczaGEv+jyfQwjTwC1V5acBfyjnnWeBY41sx5RNcux0bysM7ORwC+A0e5enWCdVL4L2Yovtg3s5ATvOwvY28wGRCXNMwjHPVeOAf7l7pX1LczV8WvgvJL772A2W/Jb0gCMIBTxyoE50XACcAFwQbTOROA9wpUdbwCH5DjGPaP3nhvFcVU0PzZGA24nXIkyDyjOcYydCCf/bjHz8nYMCUlrGbCR8EvtXKAXMB1YEL32jNYtBu6O2XY8sDAazslhfAsJddW138P/i9bdHXi6oe9CjuJ7MPpulRNOervFxxdNn0C4+uejXMYXzb+/9jsXs24+jl+i80rOv4Pq7kNERJJSNZSIiCSlZCEiIkkpWYiISFJKFiIikpSShYiIJKVkIZKEmW2yur3hZqwHVDMrjO3xVKSpapPvAESagXXuPjTfQYjkk0oWIo0UPc/gv83srWj4VjS/v5lNjzrKm25m/aL5u1h4vsTcaDgk2lVrM7srel7Bc2bWMVr/EjObH+1nSp4+pgigZCGSio5x1VCnxyz7yt1LgD8Ct0bz/kjo5n0woRO/26L5twEveegEsYhw5y/A3sDt7j4Q+BI4NZp/BTAs2s8F2fpwIqnQHdwiSZjZWnfvXM/8CuAod18Udfb2mbv3MrMvCF1YbIzmL3P3AjOrAvq6+zcx+ygkPHNg72j6F0Bbd7/BzKYBawk96z7uUQeKIvmgkoVIejzBeKJ16vNNzPgmtrYlnkjop2s4MDvqCVUkL5QsRNJzeszr69H4a4ReUgHGAa9E49OBCwHMrLWZdU20UzNrBezh7jOA/wC6A9uUbkRyRb9URJLraGZzYqanuXvt5bPtzexNwg+vsdG8S4B7zez/AVXAOdH8S4HJZnYuoQRxIaHH0/q0Bh4ys26EnoD/x92/zNgnEtlOarMQaaSozaLY3b/Idywi2aZqKBERSUolCxERSUolCxERSUrJQkREklKyEBGRpJQsREQkKSULERFJ6v8D83n/rC5qRREAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "acc_values = history_dict['acc']\n",
    "val_acc_values = history_dict['val_acc']\n",
    "epochs = range(1, len(loss_values) + 1)\n",
    "\n",
    "plt.clf() # 図を消去\n",
    "plt.plot(epochs, acc_values, 'ro', label='Training acc')\n",
    "plt.plot(epochs, val_acc_values, 'r', label='Validation acc')\n",
    "plt.title(\"Training and validation accuracy\")\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "上図を見ると、訓練データの正解率が訓練を重ねるごとに向上しているのに反して、検証データの正解率は4エポック目あたりを最高値として、徐々に下がっていっている\n",
    "\n",
    "これは**過学習**が起きていることを意味している\n",
    "\n",
    "そのため、今回の場合、訓練は4エポック程度が妥当であったと分かる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "15000/15000 [==============================] - 3s 196us/step - loss: 0.5326 - acc: 0.7917 - val_loss: 0.4064 - val_acc: 0.8700\n",
      "Epoch 2/4\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.3258 - acc: 0.8987 - val_loss: 0.3154 - val_acc: 0.8851\n",
      "Epoch 3/4\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.2357 - acc: 0.9245 - val_loss: 0.2827 - val_acc: 0.8899\n",
      "Epoch 4/4\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1866 - acc: 0.9397 - val_loss: 0.2862 - val_acc: 0.8838\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1b359000748>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4エポックで再度訓練を行う\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 2s 85us/step\n",
      "[0.3013491545677185, 0.8772]\n"
     ]
    }
   ],
   "source": [
    "# 最終結果を表示\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "今回のアプローチでは87%の正解率が達成できた\n",
    "\n",
    "なお、最先端のアプローチでは95%近い正解率を達成できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.3349126 ]\n",
      " [0.9995926 ]\n",
      " [0.9345059 ]\n",
      " ...\n",
      " [0.14445111]\n",
      " [0.19112664]\n",
      " [0.6551966 ]]\n"
     ]
    }
   ],
   "source": [
    "# 学習済みネットワークを使って予測を行う\n",
    "y_pred = model.predict(x_test)\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "正解率： 70.0016587972641 %\n"
     ]
    }
   ],
   "source": [
    "# 平均二乗誤差（MSE）で予測値の評価を行う\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ニューラルネットワークの検証\n",
    "\n",
    "　今回のアプローチでは、予測値の正解率は70%程度であり、まだまだ改善の余地がある。そこで、以下のような改善案を試してみる。\n",
    " \n",
    " - 隠れ層を1つに減らす、または3つに増やす\n",
    " - 隠れユニットを8ユニットに減らす、または32ユニットに増やす\n",
    " - 損失関数をmseに変更する\n",
    " - 活性化関数をtanhに変更する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 118us/step - loss: 0.4952 - acc: 0.7935 - val_loss: 0.3780 - val_acc: 0.8730\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.3061 - acc: 0.9070 - val_loss: 0.3101 - val_acc: 0.8910\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.2358 - acc: 0.9285 - val_loss: 0.2850 - val_acc: 0.8928\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1958 - acc: 0.9404 - val_loss: 0.2847 - val_acc: 0.8842\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1658 - acc: 0.9503 - val_loss: 0.2733 - val_acc: 0.8899\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1437 - acc: 0.9576 - val_loss: 0.2772 - val_acc: 0.8889\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1238 - acc: 0.9648 - val_loss: 0.2963 - val_acc: 0.8803\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1094 - acc: 0.9702 - val_loss: 0.2945 - val_acc: 0.8827\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0968 - acc: 0.9742 - val_loss: 0.3046 - val_acc: 0.8820\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0855 - acc: 0.9785 - val_loss: 0.3198 - val_acc: 0.8822\n",
      "25000/25000 [==============================] - 2s 82us/step\n",
      "最終結果： [0.3415111456871033, 0.86968]\n",
      "正解率： 68.9156174659729 %\n"
     ]
    }
   ],
   "source": [
    "# 隠れ層を1つに減らして学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 124us/step - loss: 0.5819 - acc: 0.7102 - val_loss: 0.4904 - val_acc: 0.8528\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 106us/step - loss: 0.3954 - acc: 0.8925 - val_loss: 0.3717 - val_acc: 0.8629\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.2654 - acc: 0.9261 - val_loss: 0.3004 - val_acc: 0.8852\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1907 - acc: 0.9438 - val_loss: 0.3068 - val_acc: 0.8807\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1480 - acc: 0.9549 - val_loss: 0.3012 - val_acc: 0.8830\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1187 - acc: 0.9641 - val_loss: 0.3233 - val_acc: 0.8788\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0960 - acc: 0.9737 - val_loss: 0.3733 - val_acc: 0.8666\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0795 - acc: 0.9777 - val_loss: 0.3792 - val_acc: 0.8720\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0645 - acc: 0.9831 - val_loss: 0.3632 - val_acc: 0.8789\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0517 - acc: 0.9876 - val_loss: 0.4034 - val_acc: 0.8738\n",
      "25000/25000 [==============================] - 2s 83us/step\n",
      "最終結果： [0.4358271631360054, 0.86176]\n",
      "正解率： 66.90393686294556 %\n"
     ]
    }
   ],
   "source": [
    "# 隠れ層を3つに増やして学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 124us/step - loss: 0.5670 - acc: 0.7787 - val_loss: 0.4763 - val_acc: 0.8260\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.3970 - acc: 0.8865 - val_loss: 0.3806 - val_acc: 0.8643\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.3055 - acc: 0.9112 - val_loss: 0.3221 - val_acc: 0.8866\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.2454 - acc: 0.9282 - val_loss: 0.3015 - val_acc: 0.8850\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.2040 - acc: 0.9385 - val_loss: 0.2834 - val_acc: 0.8886\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1726 - acc: 0.9493 - val_loss: 0.2829 - val_acc: 0.8878\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1486 - acc: 0.9557 - val_loss: 0.2755 - val_acc: 0.8895\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1289 - acc: 0.9623 - val_loss: 0.2857 - val_acc: 0.8867\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1098 - acc: 0.9694 - val_loss: 0.2911 - val_acc: 0.8870\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0958 - acc: 0.9740 - val_loss: 0.3021 - val_acc: 0.8848\n",
      "25000/25000 [==============================] - 2s 85us/step\n",
      "最終結果： [0.32580977382183074, 0.8744]\n",
      "正解率： 69.52202618122101 %\n"
     ]
    }
   ],
   "source": [
    "# 隠れユニットを8ユニットに減らして学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(8, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(8, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.4863 - acc: 0.7777 - val_loss: 0.3344 - val_acc: 0.8817\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.2683 - acc: 0.9049 - val_loss: 0.2905 - val_acc: 0.8842\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1986 - acc: 0.9284 - val_loss: 0.2871 - val_acc: 0.8855\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1565 - acc: 0.9469 - val_loss: 0.2900 - val_acc: 0.8860\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.1187 - acc: 0.9594 - val_loss: 0.3055 - val_acc: 0.8831\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.1020 - acc: 0.9656 - val_loss: 0.3316 - val_acc: 0.8822\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0793 - acc: 0.9749 - val_loss: 0.3537 - val_acc: 0.8786\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0657 - acc: 0.9797 - val_loss: 0.3852 - val_acc: 0.8787\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0514 - acc: 0.9845 - val_loss: 0.4139 - val_acc: 0.8753\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0421 - acc: 0.9878 - val_loss: 0.4433 - val_acc: 0.8763\n",
      "25000/25000 [==============================] - 2s 82us/step\n",
      "最終結果： [0.4823258297896385, 0.86136]\n",
      "正解率： 66.63058996200562 %\n"
     ]
    }
   ],
   "source": [
    "# 隠れユニットを32ユニットに増やして学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(32, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 123us/step - loss: 0.1760 - acc: 0.7816 - val_loss: 0.1255 - val_acc: 0.8638\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0962 - acc: 0.9026 - val_loss: 0.0962 - val_acc: 0.8865\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0679 - acc: 0.9298 - val_loss: 0.0869 - val_acc: 0.8893\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0520 - acc: 0.9460 - val_loss: 0.0839 - val_acc: 0.8879\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0421 - acc: 0.9574 - val_loss: 0.0828 - val_acc: 0.8880\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0337 - acc: 0.9683 - val_loss: 0.0869 - val_acc: 0.8796\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0280 - acc: 0.9735 - val_loss: 0.0858 - val_acc: 0.8832\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0229 - acc: 0.9797 - val_loss: 0.0874 - val_acc: 0.8817\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0186 - acc: 0.9849 - val_loss: 0.0932 - val_acc: 0.8765\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0149 - acc: 0.9889 - val_loss: 0.0936 - val_acc: 0.8743\n",
      "25000/25000 [==============================] - 2s 86us/step\n",
      "最終結果： [0.10328177108764648, 0.86224]\n",
      "正解率： 67.86251962184906 %\n"
     ]
    }
   ],
   "source": [
    "# 損失関数をmseに変更して学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='mse', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 127us/step - loss: 0.4662 - acc: 0.8017 - val_loss: 0.3434 - val_acc: 0.8741\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.2570 - acc: 0.9127 - val_loss: 0.2895 - val_acc: 0.8830\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1891 - acc: 0.9341 - val_loss: 0.2798 - val_acc: 0.8848\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1424 - acc: 0.9523 - val_loss: 0.2899 - val_acc: 0.8863\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1048 - acc: 0.9657 - val_loss: 0.3165 - val_acc: 0.8804\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0913 - acc: 0.9690 - val_loss: 0.3642 - val_acc: 0.8739\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0643 - acc: 0.9805 - val_loss: 0.3925 - val_acc: 0.8732\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0524 - acc: 0.9849 - val_loss: 0.4314 - val_acc: 0.8749\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0425 - acc: 0.9867 - val_loss: 0.4725 - val_acc: 0.8737\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0373 - acc: 0.9882 - val_loss: 0.5155 - val_acc: 0.8698\n",
      "25000/25000 [==============================] - 2s 83us/step\n",
      "最終結果： [0.5772876598751545, 0.85332]\n",
      "正解率： 64.90093767642975 %\n"
     ]
    }
   ],
   "source": [
    "# 活性化関数をtanhに変更して学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='tanh', input_dim=10000))\n",
    "model.add(layers.Dense(16, activation='tanh'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "15000/15000 [==============================] - 2s 137us/step - loss: 0.5714 - acc: 0.7581 - val_loss: 0.4168 - val_acc: 0.8524\n",
      "Epoch 2/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.3108 - acc: 0.8978 - val_loss: 0.2983 - val_acc: 0.8878\n",
      "Epoch 3/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.2086 - acc: 0.9304 - val_loss: 0.2769 - val_acc: 0.8894\n",
      "Epoch 4/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1516 - acc: 0.9537 - val_loss: 0.2846 - val_acc: 0.8853\n",
      "Epoch 5/10\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.1148 - acc: 0.9678 - val_loss: 0.2958 - val_acc: 0.8819\n",
      "Epoch 6/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0870 - acc: 0.9789 - val_loss: 0.3214 - val_acc: 0.8799\n",
      "Epoch 7/10\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0664 - acc: 0.9865 - val_loss: 0.3475 - val_acc: 0.8790\n",
      "Epoch 8/10\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0495 - acc: 0.9915 - val_loss: 0.3755 - val_acc: 0.8791\n",
      "Epoch 9/10\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0370 - acc: 0.9951 - val_loss: 0.4056 - val_acc: 0.8766\n",
      "Epoch 10/10\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0284 - acc: 0.9972 - val_loss: 0.4356 - val_acc: 0.8755\n",
      "25000/25000 [==============================] - 2s 91us/step\n",
      "最終結果： [0.46791258397102353, 0.86068]\n",
      "正解率： 66.70599281787872 %\n"
     ]
    }
   ],
   "source": [
    "# オプティマイザをadamに変更して学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(16, activation='relu', input_dim=10000))\n",
    "model.add(layers.Dense(16, activation='relu'))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=10, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/1000\n",
      "15000/15000 [==============================] - 2s 132us/step - loss: 0.6132 - acc: 0.7462 - val_loss: 0.5594 - val_acc: 0.8168\n",
      "Epoch 2/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.5154 - acc: 0.8431 - val_loss: 0.4961 - val_acc: 0.8406\n",
      "Epoch 3/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.4544 - acc: 0.8669 - val_loss: 0.4510 - val_acc: 0.8558\n",
      "Epoch 4/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.4087 - acc: 0.8817 - val_loss: 0.4176 - val_acc: 0.8625\n",
      "Epoch 5/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.3735 - acc: 0.8937 - val_loss: 0.3919 - val_acc: 0.8675\n",
      "Epoch 6/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.3454 - acc: 0.8997 - val_loss: 0.3718 - val_acc: 0.8737\n",
      "Epoch 7/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.3221 - acc: 0.9071 - val_loss: 0.3552 - val_acc: 0.8778\n",
      "Epoch 8/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.3026 - acc: 0.9120 - val_loss: 0.3417 - val_acc: 0.8805\n",
      "Epoch 9/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.2861 - acc: 0.9177 - val_loss: 0.3323 - val_acc: 0.8810\n",
      "Epoch 10/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.2722 - acc: 0.9221 - val_loss: 0.3226 - val_acc: 0.8846\n",
      "Epoch 11/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.2595 - acc: 0.9265 - val_loss: 0.3151 - val_acc: 0.8858\n",
      "Epoch 12/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.2486 - acc: 0.9295 - val_loss: 0.3086 - val_acc: 0.8872\n",
      "Epoch 13/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.2385 - acc: 0.9327 - val_loss: 0.3029 - val_acc: 0.8881\n",
      "Epoch 14/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.2296 - acc: 0.9353 - val_loss: 0.2999 - val_acc: 0.8865\n",
      "Epoch 15/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.2217 - acc: 0.9379 - val_loss: 0.2943 - val_acc: 0.8885\n",
      "Epoch 16/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.2142 - acc: 0.9401 - val_loss: 0.2910 - val_acc: 0.8892\n",
      "Epoch 17/1000\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.2075 - acc: 0.9421 - val_loss: 0.2880 - val_acc: 0.8895\n",
      "Epoch 18/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.2010 - acc: 0.9443 - val_loss: 0.2857 - val_acc: 0.8907\n",
      "Epoch 19/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1952 - acc: 0.9461 - val_loss: 0.2834 - val_acc: 0.8898\n",
      "Epoch 20/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1898 - acc: 0.9480 - val_loss: 0.2815 - val_acc: 0.8897\n",
      "Epoch 21/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1846 - acc: 0.9503 - val_loss: 0.2802 - val_acc: 0.8909\n",
      "Epoch 22/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1799 - acc: 0.9522 - val_loss: 0.2786 - val_acc: 0.8912\n",
      "Epoch 23/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1753 - acc: 0.9540 - val_loss: 0.2783 - val_acc: 0.8899\n",
      "Epoch 24/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1711 - acc: 0.9540 - val_loss: 0.2769 - val_acc: 0.8908\n",
      "Epoch 25/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1669 - acc: 0.9553 - val_loss: 0.2769 - val_acc: 0.8903\n",
      "Epoch 26/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1634 - acc: 0.9563 - val_loss: 0.2760 - val_acc: 0.8910\n",
      "Epoch 27/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1597 - acc: 0.9574 - val_loss: 0.2749 - val_acc: 0.8920\n",
      "Epoch 28/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.1561 - acc: 0.9593 - val_loss: 0.2744 - val_acc: 0.8918\n",
      "Epoch 29/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1527 - acc: 0.9598 - val_loss: 0.2742 - val_acc: 0.8918\n",
      "Epoch 30/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1496 - acc: 0.9612 - val_loss: 0.2740 - val_acc: 0.8918\n",
      "Epoch 31/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1466 - acc: 0.9616 - val_loss: 0.2740 - val_acc: 0.8914\n",
      "Epoch 32/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1437 - acc: 0.9625 - val_loss: 0.2743 - val_acc: 0.8908\n",
      "Epoch 33/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1409 - acc: 0.9635 - val_loss: 0.2741 - val_acc: 0.8919\n",
      "Epoch 34/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1380 - acc: 0.9647 - val_loss: 0.2749 - val_acc: 0.8895\n",
      "Epoch 35/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1356 - acc: 0.9652 - val_loss: 0.2748 - val_acc: 0.8905\n",
      "Epoch 36/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1330 - acc: 0.9664 - val_loss: 0.2749 - val_acc: 0.8909\n",
      "Epoch 37/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1306 - acc: 0.9679 - val_loss: 0.2753 - val_acc: 0.8909\n",
      "Epoch 38/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1282 - acc: 0.9678 - val_loss: 0.2757 - val_acc: 0.8909\n",
      "Epoch 39/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1260 - acc: 0.9698 - val_loss: 0.2762 - val_acc: 0.8904\n",
      "Epoch 40/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1238 - acc: 0.9701 - val_loss: 0.2771 - val_acc: 0.8891\n",
      "Epoch 41/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1217 - acc: 0.9706 - val_loss: 0.2771 - val_acc: 0.8901\n",
      "Epoch 42/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1197 - acc: 0.9716 - val_loss: 0.2777 - val_acc: 0.8893\n",
      "Epoch 43/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1177 - acc: 0.9721 - val_loss: 0.2785 - val_acc: 0.8892\n",
      "Epoch 44/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1157 - acc: 0.9734 - val_loss: 0.2796 - val_acc: 0.8883\n",
      "Epoch 45/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1139 - acc: 0.9740 - val_loss: 0.2795 - val_acc: 0.8890\n",
      "Epoch 46/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.1120 - acc: 0.9745 - val_loss: 0.2805 - val_acc: 0.8880\n",
      "Epoch 47/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1103 - acc: 0.9745 - val_loss: 0.2808 - val_acc: 0.8886\n",
      "Epoch 48/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.1084 - acc: 0.9754 - val_loss: 0.2818 - val_acc: 0.8879\n",
      "Epoch 49/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1068 - acc: 0.9756 - val_loss: 0.2824 - val_acc: 0.8884\n",
      "Epoch 50/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1051 - acc: 0.9766 - val_loss: 0.2834 - val_acc: 0.8878\n",
      "Epoch 51/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.1035 - acc: 0.9768 - val_loss: 0.2843 - val_acc: 0.8876\n",
      "Epoch 52/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1020 - acc: 0.9773 - val_loss: 0.2849 - val_acc: 0.8868\n",
      "Epoch 53/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.1004 - acc: 0.9777 - val_loss: 0.2858 - val_acc: 0.8864\n",
      "Epoch 54/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0989 - acc: 0.9781 - val_loss: 0.2867 - val_acc: 0.8859\n",
      "Epoch 55/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0975 - acc: 0.9789 - val_loss: 0.2877 - val_acc: 0.8863\n",
      "Epoch 56/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0961 - acc: 0.9789 - val_loss: 0.2885 - val_acc: 0.8857\n",
      "Epoch 57/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0947 - acc: 0.9795 - val_loss: 0.2894 - val_acc: 0.8853\n",
      "Epoch 58/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0933 - acc: 0.9796 - val_loss: 0.2905 - val_acc: 0.8850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0920 - acc: 0.9802 - val_loss: 0.2914 - val_acc: 0.8851\n",
      "Epoch 60/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0908 - acc: 0.9812 - val_loss: 0.2925 - val_acc: 0.8856\n",
      "Epoch 61/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0894 - acc: 0.9815 - val_loss: 0.2934 - val_acc: 0.8853\n",
      "Epoch 62/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0882 - acc: 0.9819 - val_loss: 0.2949 - val_acc: 0.8854\n",
      "Epoch 63/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0870 - acc: 0.9821 - val_loss: 0.2958 - val_acc: 0.8847\n",
      "Epoch 64/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0858 - acc: 0.9823 - val_loss: 0.2965 - val_acc: 0.8846\n",
      "Epoch 65/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0845 - acc: 0.9827 - val_loss: 0.2977 - val_acc: 0.8848\n",
      "Epoch 66/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0835 - acc: 0.9832 - val_loss: 0.2987 - val_acc: 0.8843\n",
      "Epoch 67/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0823 - acc: 0.9835 - val_loss: 0.2997 - val_acc: 0.8840\n",
      "Epoch 68/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0812 - acc: 0.9841 - val_loss: 0.3009 - val_acc: 0.8841\n",
      "Epoch 69/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0802 - acc: 0.9841 - val_loss: 0.3019 - val_acc: 0.8838\n",
      "Epoch 70/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0790 - acc: 0.9849 - val_loss: 0.3033 - val_acc: 0.8838\n",
      "Epoch 71/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0780 - acc: 0.9851 - val_loss: 0.3040 - val_acc: 0.8836\n",
      "Epoch 72/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0769 - acc: 0.9853 - val_loss: 0.3054 - val_acc: 0.8831\n",
      "Epoch 73/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0760 - acc: 0.9856 - val_loss: 0.3062 - val_acc: 0.8832\n",
      "Epoch 74/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0750 - acc: 0.9859 - val_loss: 0.3074 - val_acc: 0.8830\n",
      "Epoch 75/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0741 - acc: 0.9861 - val_loss: 0.3085 - val_acc: 0.8831\n",
      "Epoch 76/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0731 - acc: 0.9865 - val_loss: 0.3098 - val_acc: 0.8825\n",
      "Epoch 77/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0722 - acc: 0.9872 - val_loss: 0.3108 - val_acc: 0.8827\n",
      "Epoch 78/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0713 - acc: 0.9870 - val_loss: 0.3120 - val_acc: 0.8830\n",
      "Epoch 79/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0704 - acc: 0.9873 - val_loss: 0.3131 - val_acc: 0.8824\n",
      "Epoch 80/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0695 - acc: 0.9878 - val_loss: 0.3143 - val_acc: 0.8819\n",
      "Epoch 81/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0686 - acc: 0.9882 - val_loss: 0.3155 - val_acc: 0.8822\n",
      "Epoch 82/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0678 - acc: 0.9883 - val_loss: 0.3170 - val_acc: 0.8825\n",
      "Epoch 83/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0669 - acc: 0.9891 - val_loss: 0.3183 - val_acc: 0.8820\n",
      "Epoch 84/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0661 - acc: 0.9891 - val_loss: 0.3191 - val_acc: 0.8824\n",
      "Epoch 85/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0654 - acc: 0.9885 - val_loss: 0.3202 - val_acc: 0.8815\n",
      "Epoch 86/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0645 - acc: 0.9892 - val_loss: 0.3214 - val_acc: 0.8816\n",
      "Epoch 87/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0638 - acc: 0.9898 - val_loss: 0.3225 - val_acc: 0.8815\n",
      "Epoch 88/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0629 - acc: 0.9896 - val_loss: 0.3239 - val_acc: 0.8825\n",
      "Epoch 89/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0622 - acc: 0.9898 - val_loss: 0.3250 - val_acc: 0.8816\n",
      "Epoch 90/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0616 - acc: 0.9899 - val_loss: 0.3261 - val_acc: 0.8812\n",
      "Epoch 91/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0607 - acc: 0.9903 - val_loss: 0.3273 - val_acc: 0.8816\n",
      "Epoch 92/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0600 - acc: 0.9905 - val_loss: 0.3285 - val_acc: 0.8816\n",
      "Epoch 93/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0593 - acc: 0.9907 - val_loss: 0.3298 - val_acc: 0.8815\n",
      "Epoch 94/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0586 - acc: 0.9907 - val_loss: 0.3309 - val_acc: 0.8817\n",
      "Epoch 95/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0579 - acc: 0.9909 - val_loss: 0.3321 - val_acc: 0.8816\n",
      "Epoch 96/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0573 - acc: 0.9915 - val_loss: 0.3333 - val_acc: 0.8811\n",
      "Epoch 97/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0566 - acc: 0.9915 - val_loss: 0.3347 - val_acc: 0.8799\n",
      "Epoch 98/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0559 - acc: 0.9919 - val_loss: 0.3359 - val_acc: 0.8802\n",
      "Epoch 99/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0552 - acc: 0.9921 - val_loss: 0.3373 - val_acc: 0.8800\n",
      "Epoch 100/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0546 - acc: 0.9919 - val_loss: 0.3388 - val_acc: 0.8800\n",
      "Epoch 101/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0540 - acc: 0.9924 - val_loss: 0.3396 - val_acc: 0.8803\n",
      "Epoch 102/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0533 - acc: 0.9923 - val_loss: 0.3408 - val_acc: 0.8802\n",
      "Epoch 103/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0527 - acc: 0.9926 - val_loss: 0.3423 - val_acc: 0.8791\n",
      "Epoch 104/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0521 - acc: 0.9929 - val_loss: 0.3434 - val_acc: 0.8800\n",
      "Epoch 105/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0515 - acc: 0.9926 - val_loss: 0.3445 - val_acc: 0.8796\n",
      "Epoch 106/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0509 - acc: 0.9932 - val_loss: 0.3459 - val_acc: 0.8795\n",
      "Epoch 107/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0504 - acc: 0.9933 - val_loss: 0.3471 - val_acc: 0.8794\n",
      "Epoch 108/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0498 - acc: 0.9937 - val_loss: 0.3483 - val_acc: 0.8793\n",
      "Epoch 109/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0492 - acc: 0.9935 - val_loss: 0.3498 - val_acc: 0.8785\n",
      "Epoch 110/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0487 - acc: 0.9937 - val_loss: 0.3508 - val_acc: 0.8789\n",
      "Epoch 111/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0481 - acc: 0.9939 - val_loss: 0.3522 - val_acc: 0.8787\n",
      "Epoch 112/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0476 - acc: 0.9940 - val_loss: 0.3536 - val_acc: 0.8780\n",
      "Epoch 113/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0470 - acc: 0.9941 - val_loss: 0.3547 - val_acc: 0.8783\n",
      "Epoch 114/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0465 - acc: 0.9941 - val_loss: 0.3562 - val_acc: 0.8786\n",
      "Epoch 115/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0460 - acc: 0.9943 - val_loss: 0.3572 - val_acc: 0.8781\n",
      "Epoch 116/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0455 - acc: 0.9944 - val_loss: 0.3584 - val_acc: 0.8772\n",
      "Epoch 117/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0450 - acc: 0.9946 - val_loss: 0.3597 - val_acc: 0.8772\n",
      "Epoch 118/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0445 - acc: 0.9949 - val_loss: 0.3609 - val_acc: 0.8772\n",
      "Epoch 119/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0440 - acc: 0.9948 - val_loss: 0.3621 - val_acc: 0.8773\n",
      "Epoch 120/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0435 - acc: 0.9949 - val_loss: 0.3635 - val_acc: 0.8769\n",
      "Epoch 121/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0430 - acc: 0.9952 - val_loss: 0.3648 - val_acc: 0.8767\n",
      "Epoch 122/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0426 - acc: 0.9950 - val_loss: 0.3666 - val_acc: 0.8777\n",
      "Epoch 123/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0421 - acc: 0.9951 - val_loss: 0.3673 - val_acc: 0.8769\n",
      "Epoch 124/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0417 - acc: 0.9953 - val_loss: 0.3686 - val_acc: 0.8764\n",
      "Epoch 125/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0412 - acc: 0.9953 - val_loss: 0.3701 - val_acc: 0.8763\n",
      "Epoch 126/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0408 - acc: 0.9954 - val_loss: 0.3712 - val_acc: 0.8763\n",
      "Epoch 127/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0403 - acc: 0.9956 - val_loss: 0.3725 - val_acc: 0.8761\n",
      "Epoch 128/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0399 - acc: 0.9956 - val_loss: 0.3740 - val_acc: 0.8752\n",
      "Epoch 129/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0394 - acc: 0.9955 - val_loss: 0.3751 - val_acc: 0.8752\n",
      "Epoch 130/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0390 - acc: 0.9957 - val_loss: 0.3765 - val_acc: 0.8756\n",
      "Epoch 131/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0386 - acc: 0.9959 - val_loss: 0.3779 - val_acc: 0.8754\n",
      "Epoch 132/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0382 - acc: 0.9959 - val_loss: 0.3791 - val_acc: 0.8745\n",
      "Epoch 133/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0378 - acc: 0.9962 - val_loss: 0.3808 - val_acc: 0.8748\n",
      "Epoch 134/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0373 - acc: 0.9961 - val_loss: 0.3816 - val_acc: 0.8745\n",
      "Epoch 135/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0369 - acc: 0.9963 - val_loss: 0.3829 - val_acc: 0.8740\n",
      "Epoch 136/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0366 - acc: 0.9961 - val_loss: 0.3843 - val_acc: 0.8736\n",
      "Epoch 137/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0362 - acc: 0.9963 - val_loss: 0.3857 - val_acc: 0.8735\n",
      "Epoch 138/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0358 - acc: 0.9962 - val_loss: 0.3871 - val_acc: 0.8735\n",
      "Epoch 139/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0354 - acc: 0.9964 - val_loss: 0.3887 - val_acc: 0.8738\n",
      "Epoch 140/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0350 - acc: 0.9964 - val_loss: 0.3899 - val_acc: 0.8739\n",
      "Epoch 141/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0347 - acc: 0.9965 - val_loss: 0.3912 - val_acc: 0.8726\n",
      "Epoch 142/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0343 - acc: 0.9965 - val_loss: 0.3922 - val_acc: 0.8734\n",
      "Epoch 143/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0340 - acc: 0.9965 - val_loss: 0.3941 - val_acc: 0.8719\n",
      "Epoch 144/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0336 - acc: 0.9965 - val_loss: 0.3949 - val_acc: 0.8717\n",
      "Epoch 145/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0332 - acc: 0.9967 - val_loss: 0.3963 - val_acc: 0.8722\n",
      "Epoch 146/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0329 - acc: 0.9967 - val_loss: 0.3975 - val_acc: 0.8729\n",
      "Epoch 147/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0325 - acc: 0.9967 - val_loss: 0.3991 - val_acc: 0.8713\n",
      "Epoch 148/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0322 - acc: 0.9967 - val_loss: 0.4001 - val_acc: 0.8721\n",
      "Epoch 149/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0319 - acc: 0.9968 - val_loss: 0.4014 - val_acc: 0.8717\n",
      "Epoch 150/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0315 - acc: 0.9969 - val_loss: 0.4028 - val_acc: 0.8715\n",
      "Epoch 151/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0312 - acc: 0.9969 - val_loss: 0.4042 - val_acc: 0.8716\n",
      "Epoch 152/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0309 - acc: 0.9969 - val_loss: 0.4056 - val_acc: 0.8718\n",
      "Epoch 153/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0305 - acc: 0.9969 - val_loss: 0.4070 - val_acc: 0.8708\n",
      "Epoch 154/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0302 - acc: 0.9972 - val_loss: 0.4084 - val_acc: 0.8717\n",
      "Epoch 155/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0299 - acc: 0.9969 - val_loss: 0.4094 - val_acc: 0.8709\n",
      "Epoch 156/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0296 - acc: 0.9971 - val_loss: 0.4108 - val_acc: 0.8705\n",
      "Epoch 157/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0293 - acc: 0.9970 - val_loss: 0.4121 - val_acc: 0.8706\n",
      "Epoch 158/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0290 - acc: 0.9971 - val_loss: 0.4135 - val_acc: 0.8703\n",
      "Epoch 159/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0287 - acc: 0.9974 - val_loss: 0.4148 - val_acc: 0.8704\n",
      "Epoch 160/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0284 - acc: 0.9975 - val_loss: 0.4163 - val_acc: 0.8704\n",
      "Epoch 161/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0281 - acc: 0.9976 - val_loss: 0.4179 - val_acc: 0.8698\n",
      "Epoch 162/1000\n",
      "15000/15000 [==============================] - 2s 106us/step - loss: 0.0278 - acc: 0.9977 - val_loss: 0.4188 - val_acc: 0.8696\n",
      "Epoch 163/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0275 - acc: 0.9977 - val_loss: 0.4202 - val_acc: 0.8698\n",
      "Epoch 164/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0272 - acc: 0.9978 - val_loss: 0.4215 - val_acc: 0.8696\n",
      "Epoch 165/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0270 - acc: 0.9980 - val_loss: 0.4231 - val_acc: 0.8705\n",
      "Epoch 166/1000\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 0.0267 - acc: 0.9979 - val_loss: 0.4242 - val_acc: 0.8698\n",
      "Epoch 167/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0264 - acc: 0.9979 - val_loss: 0.4257 - val_acc: 0.8690\n",
      "Epoch 168/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0262 - acc: 0.9981 - val_loss: 0.4268 - val_acc: 0.8697\n",
      "Epoch 169/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0259 - acc: 0.9981 - val_loss: 0.4284 - val_acc: 0.8695\n",
      "Epoch 170/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0256 - acc: 0.9981 - val_loss: 0.4296 - val_acc: 0.8689\n",
      "Epoch 171/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0254 - acc: 0.9983 - val_loss: 0.4309 - val_acc: 0.8696\n",
      "Epoch 172/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0251 - acc: 0.9983 - val_loss: 0.4322 - val_acc: 0.8698\n",
      "Epoch 173/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0249 - acc: 0.9983 - val_loss: 0.4338 - val_acc: 0.8679\n",
      "Epoch 174/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0246 - acc: 0.9984 - val_loss: 0.4352 - val_acc: 0.8681\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 175/1000\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.0244 - acc: 0.9985 - val_loss: 0.4361 - val_acc: 0.8688\n",
      "Epoch 176/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0241 - acc: 0.9985 - val_loss: 0.4375 - val_acc: 0.8687\n",
      "Epoch 177/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0238 - acc: 0.9984 - val_loss: 0.4388 - val_acc: 0.8688\n",
      "Epoch 178/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0236 - acc: 0.9985 - val_loss: 0.4402 - val_acc: 0.8692\n",
      "Epoch 179/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0234 - acc: 0.9985 - val_loss: 0.4416 - val_acc: 0.8685\n",
      "Epoch 180/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0231 - acc: 0.9985 - val_loss: 0.4429 - val_acc: 0.8680\n",
      "Epoch 181/1000\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0229 - acc: 0.9985 - val_loss: 0.4444 - val_acc: 0.8680\n",
      "Epoch 182/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0227 - acc: 0.9986 - val_loss: 0.4461 - val_acc: 0.8676\n",
      "Epoch 183/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0224 - acc: 0.9986 - val_loss: 0.4469 - val_acc: 0.8685\n",
      "Epoch 184/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0222 - acc: 0.9986 - val_loss: 0.4482 - val_acc: 0.8687\n",
      "Epoch 185/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0220 - acc: 0.9987 - val_loss: 0.4496 - val_acc: 0.8686\n",
      "Epoch 186/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0218 - acc: 0.9987 - val_loss: 0.4509 - val_acc: 0.8686\n",
      "Epoch 187/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0216 - acc: 0.9988 - val_loss: 0.4523 - val_acc: 0.8677\n",
      "Epoch 188/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0213 - acc: 0.9988 - val_loss: 0.4537 - val_acc: 0.8682\n",
      "Epoch 189/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0211 - acc: 0.9989 - val_loss: 0.4550 - val_acc: 0.8677\n",
      "Epoch 190/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0209 - acc: 0.9989 - val_loss: 0.4565 - val_acc: 0.8674\n",
      "Epoch 191/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0207 - acc: 0.9990 - val_loss: 0.4575 - val_acc: 0.8685\n",
      "Epoch 192/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0205 - acc: 0.9991 - val_loss: 0.4591 - val_acc: 0.8674\n",
      "Epoch 193/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0203 - acc: 0.9991 - val_loss: 0.4602 - val_acc: 0.8685\n",
      "Epoch 194/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0201 - acc: 0.9993 - val_loss: 0.4616 - val_acc: 0.8676\n",
      "Epoch 195/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0199 - acc: 0.9991 - val_loss: 0.4629 - val_acc: 0.8674\n",
      "Epoch 196/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0197 - acc: 0.9992 - val_loss: 0.4642 - val_acc: 0.8681\n",
      "Epoch 197/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0195 - acc: 0.9993 - val_loss: 0.4657 - val_acc: 0.8672\n",
      "Epoch 198/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0193 - acc: 0.9992 - val_loss: 0.4670 - val_acc: 0.8679\n",
      "Epoch 199/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0191 - acc: 0.9993 - val_loss: 0.4683 - val_acc: 0.8676\n",
      "Epoch 200/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0189 - acc: 0.9993 - val_loss: 0.4700 - val_acc: 0.8664\n",
      "Epoch 201/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0187 - acc: 0.9993 - val_loss: 0.4711 - val_acc: 0.8677\n",
      "Epoch 202/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0185 - acc: 0.9993 - val_loss: 0.4724 - val_acc: 0.8674\n",
      "Epoch 203/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0183 - acc: 0.9993 - val_loss: 0.4738 - val_acc: 0.8666\n",
      "Epoch 204/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0182 - acc: 0.9993 - val_loss: 0.4749 - val_acc: 0.8672\n",
      "Epoch 205/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0180 - acc: 0.9993 - val_loss: 0.4763 - val_acc: 0.8672\n",
      "Epoch 206/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0178 - acc: 0.9993 - val_loss: 0.4777 - val_acc: 0.8672\n",
      "Epoch 207/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0176 - acc: 0.9993 - val_loss: 0.4789 - val_acc: 0.8666\n",
      "Epoch 208/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0175 - acc: 0.9994 - val_loss: 0.4805 - val_acc: 0.8667\n",
      "Epoch 209/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0173 - acc: 0.9993 - val_loss: 0.4816 - val_acc: 0.8667\n",
      "Epoch 210/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0171 - acc: 0.9993 - val_loss: 0.4833 - val_acc: 0.8663\n",
      "Epoch 211/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0169 - acc: 0.9995 - val_loss: 0.4842 - val_acc: 0.8663\n",
      "Epoch 212/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0168 - acc: 0.9995 - val_loss: 0.4857 - val_acc: 0.8663\n",
      "Epoch 213/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0166 - acc: 0.9994 - val_loss: 0.4870 - val_acc: 0.8662\n",
      "Epoch 214/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0164 - acc: 0.9995 - val_loss: 0.4884 - val_acc: 0.8658\n",
      "Epoch 215/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0163 - acc: 0.9995 - val_loss: 0.4898 - val_acc: 0.8658\n",
      "Epoch 216/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0161 - acc: 0.9995 - val_loss: 0.4912 - val_acc: 0.8669\n",
      "Epoch 217/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0159 - acc: 0.9995 - val_loss: 0.4925 - val_acc: 0.8662\n",
      "Epoch 218/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0158 - acc: 0.9995 - val_loss: 0.4938 - val_acc: 0.8659\n",
      "Epoch 219/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0156 - acc: 0.9995 - val_loss: 0.4951 - val_acc: 0.8658\n",
      "Epoch 220/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0155 - acc: 0.9995 - val_loss: 0.4965 - val_acc: 0.8664\n",
      "Epoch 221/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0153 - acc: 0.9995 - val_loss: 0.4978 - val_acc: 0.8662\n",
      "Epoch 222/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0152 - acc: 0.9995 - val_loss: 0.4992 - val_acc: 0.8657\n",
      "Epoch 223/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0150 - acc: 0.9995 - val_loss: 0.5006 - val_acc: 0.8653\n",
      "Epoch 224/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0149 - acc: 0.9996 - val_loss: 0.5017 - val_acc: 0.8657\n",
      "Epoch 225/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0147 - acc: 0.9997 - val_loss: 0.5035 - val_acc: 0.8652\n",
      "Epoch 226/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0146 - acc: 0.9997 - val_loss: 0.5044 - val_acc: 0.8661\n",
      "Epoch 227/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0145 - acc: 0.9997 - val_loss: 0.5058 - val_acc: 0.8658\n",
      "Epoch 228/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0143 - acc: 0.9997 - val_loss: 0.5073 - val_acc: 0.8654\n",
      "Epoch 229/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0142 - acc: 0.9997 - val_loss: 0.5085 - val_acc: 0.8654\n",
      "Epoch 230/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0140 - acc: 0.9997 - val_loss: 0.5100 - val_acc: 0.8654\n",
      "Epoch 231/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0139 - acc: 0.9997 - val_loss: 0.5112 - val_acc: 0.8658\n",
      "Epoch 232/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0137 - acc: 0.9997 - val_loss: 0.5124 - val_acc: 0.8657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 233/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0136 - acc: 0.9997 - val_loss: 0.5138 - val_acc: 0.8658\n",
      "Epoch 234/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0135 - acc: 0.9997 - val_loss: 0.5152 - val_acc: 0.8654\n",
      "Epoch 235/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0134 - acc: 0.9997 - val_loss: 0.5164 - val_acc: 0.8656\n",
      "Epoch 236/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0132 - acc: 0.9997 - val_loss: 0.5180 - val_acc: 0.8655\n",
      "Epoch 237/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0131 - acc: 0.9997 - val_loss: 0.5192 - val_acc: 0.8657\n",
      "Epoch 238/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0130 - acc: 0.9997 - val_loss: 0.5205 - val_acc: 0.8652\n",
      "Epoch 239/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0128 - acc: 0.9997 - val_loss: 0.5218 - val_acc: 0.8650\n",
      "Epoch 240/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0127 - acc: 0.9997 - val_loss: 0.5232 - val_acc: 0.8650\n",
      "Epoch 241/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0126 - acc: 0.9997 - val_loss: 0.5244 - val_acc: 0.8653\n",
      "Epoch 242/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0125 - acc: 0.9997 - val_loss: 0.5257 - val_acc: 0.8651\n",
      "Epoch 243/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0123 - acc: 0.9997 - val_loss: 0.5272 - val_acc: 0.8648\n",
      "Epoch 244/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0122 - acc: 0.9997 - val_loss: 0.5286 - val_acc: 0.8649\n",
      "Epoch 245/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0121 - acc: 0.9997 - val_loss: 0.5297 - val_acc: 0.8647\n",
      "Epoch 246/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0120 - acc: 0.9997 - val_loss: 0.5311 - val_acc: 0.8648\n",
      "Epoch 247/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0119 - acc: 0.9997 - val_loss: 0.5324 - val_acc: 0.8647\n",
      "Epoch 248/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0117 - acc: 0.9997 - val_loss: 0.5339 - val_acc: 0.8642\n",
      "Epoch 249/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0116 - acc: 0.9997 - val_loss: 0.5353 - val_acc: 0.8645\n",
      "Epoch 250/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0115 - acc: 0.9997 - val_loss: 0.5364 - val_acc: 0.8642\n",
      "Epoch 251/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0114 - acc: 0.9997 - val_loss: 0.5378 - val_acc: 0.8643\n",
      "Epoch 252/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0113 - acc: 0.9997 - val_loss: 0.5391 - val_acc: 0.8636\n",
      "Epoch 253/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0112 - acc: 0.9997 - val_loss: 0.5404 - val_acc: 0.8640\n",
      "Epoch 254/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0111 - acc: 0.9998 - val_loss: 0.5417 - val_acc: 0.8640\n",
      "Epoch 255/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0110 - acc: 0.9998 - val_loss: 0.5430 - val_acc: 0.8637\n",
      "Epoch 256/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0109 - acc: 0.9998 - val_loss: 0.5444 - val_acc: 0.8639\n",
      "Epoch 257/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0108 - acc: 0.9998 - val_loss: 0.5456 - val_acc: 0.8639\n",
      "Epoch 258/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0106 - acc: 0.9998 - val_loss: 0.5469 - val_acc: 0.8639\n",
      "Epoch 259/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0106 - acc: 0.9998 - val_loss: 0.5482 - val_acc: 0.8639\n",
      "Epoch 260/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0105 - acc: 0.9998 - val_loss: 0.5495 - val_acc: 0.8639\n",
      "Epoch 261/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0103 - acc: 0.9998 - val_loss: 0.5508 - val_acc: 0.8636\n",
      "Epoch 262/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0102 - acc: 0.9998 - val_loss: 0.5522 - val_acc: 0.8635\n",
      "Epoch 263/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0101 - acc: 0.9997 - val_loss: 0.5534 - val_acc: 0.8633\n",
      "Epoch 264/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0101 - acc: 0.9998 - val_loss: 0.5547 - val_acc: 0.8633\n",
      "Epoch 265/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0100 - acc: 0.9998 - val_loss: 0.5564 - val_acc: 0.8638\n",
      "Epoch 266/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0099 - acc: 0.9998 - val_loss: 0.5575 - val_acc: 0.8635\n",
      "Epoch 267/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0098 - acc: 0.9999 - val_loss: 0.5590 - val_acc: 0.8635\n",
      "Epoch 268/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0097 - acc: 0.9998 - val_loss: 0.5601 - val_acc: 0.8636\n",
      "Epoch 269/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0096 - acc: 0.9999 - val_loss: 0.5613 - val_acc: 0.8638\n",
      "Epoch 270/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0095 - acc: 0.9999 - val_loss: 0.5628 - val_acc: 0.8634\n",
      "Epoch 271/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0094 - acc: 0.9999 - val_loss: 0.5645 - val_acc: 0.8626\n",
      "Epoch 272/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0093 - acc: 0.9999 - val_loss: 0.5654 - val_acc: 0.8637\n",
      "Epoch 273/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0092 - acc: 0.9999 - val_loss: 0.5667 - val_acc: 0.8633\n",
      "Epoch 274/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0091 - acc: 0.9999 - val_loss: 0.5681 - val_acc: 0.8635\n",
      "Epoch 275/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0090 - acc: 0.9999 - val_loss: 0.5694 - val_acc: 0.8633\n",
      "Epoch 276/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0090 - acc: 0.9999 - val_loss: 0.5711 - val_acc: 0.8629\n",
      "Epoch 277/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0089 - acc: 0.9999 - val_loss: 0.5721 - val_acc: 0.8630\n",
      "Epoch 278/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0088 - acc: 0.9999 - val_loss: 0.5736 - val_acc: 0.8628\n",
      "Epoch 279/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0087 - acc: 0.9999 - val_loss: 0.5751 - val_acc: 0.8625\n",
      "Epoch 280/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0086 - acc: 0.9999 - val_loss: 0.5762 - val_acc: 0.8631\n",
      "Epoch 281/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0085 - acc: 0.9999 - val_loss: 0.5779 - val_acc: 0.8620\n",
      "Epoch 282/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0084 - acc: 0.9999 - val_loss: 0.5789 - val_acc: 0.8630\n",
      "Epoch 283/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0084 - acc: 0.9999 - val_loss: 0.5804 - val_acc: 0.8629\n",
      "Epoch 284/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0083 - acc: 0.9999 - val_loss: 0.5819 - val_acc: 0.8627\n",
      "Epoch 285/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0082 - acc: 0.9999 - val_loss: 0.5830 - val_acc: 0.8630\n",
      "Epoch 286/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0081 - acc: 0.9999 - val_loss: 0.5844 - val_acc: 0.8629\n",
      "Epoch 287/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0080 - acc: 0.9999 - val_loss: 0.5859 - val_acc: 0.8623\n",
      "Epoch 288/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0080 - acc: 0.9999 - val_loss: 0.5873 - val_acc: 0.8626\n",
      "Epoch 289/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0079 - acc: 0.9999 - val_loss: 0.5885 - val_acc: 0.8625\n",
      "Epoch 290/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0078 - acc: 0.9999 - val_loss: 0.5897 - val_acc: 0.8629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 291/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0077 - acc: 0.9999 - val_loss: 0.5909 - val_acc: 0.8631\n",
      "Epoch 292/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0077 - acc: 0.9999 - val_loss: 0.5924 - val_acc: 0.8621\n",
      "Epoch 293/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0076 - acc: 0.9999 - val_loss: 0.5935 - val_acc: 0.8630\n",
      "Epoch 294/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0075 - acc: 0.9999 - val_loss: 0.5949 - val_acc: 0.8625\n",
      "Epoch 295/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0074 - acc: 0.9999 - val_loss: 0.5963 - val_acc: 0.8623\n",
      "Epoch 296/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0074 - acc: 0.9999 - val_loss: 0.5975 - val_acc: 0.8625\n",
      "Epoch 297/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0073 - acc: 0.9999 - val_loss: 0.5989 - val_acc: 0.8624\n",
      "Epoch 298/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0072 - acc: 0.9999 - val_loss: 0.6002 - val_acc: 0.8625\n",
      "Epoch 299/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0072 - acc: 0.9999 - val_loss: 0.6017 - val_acc: 0.8617\n",
      "Epoch 300/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0071 - acc: 0.9999 - val_loss: 0.6030 - val_acc: 0.8624\n",
      "Epoch 301/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0070 - acc: 0.9999 - val_loss: 0.6044 - val_acc: 0.8624\n",
      "Epoch 302/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0070 - acc: 0.9999 - val_loss: 0.6057 - val_acc: 0.8625\n",
      "Epoch 303/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0069 - acc: 0.9999 - val_loss: 0.6071 - val_acc: 0.8624\n",
      "Epoch 304/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0068 - acc: 0.9999 - val_loss: 0.6084 - val_acc: 0.8624\n",
      "Epoch 305/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0068 - acc: 0.9999 - val_loss: 0.6097 - val_acc: 0.8624\n",
      "Epoch 306/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0067 - acc: 0.9999 - val_loss: 0.6112 - val_acc: 0.8620\n",
      "Epoch 307/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0066 - acc: 0.9999 - val_loss: 0.6123 - val_acc: 0.8624\n",
      "Epoch 308/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0066 - acc: 0.9999 - val_loss: 0.6138 - val_acc: 0.8617\n",
      "Epoch 309/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0065 - acc: 0.9999 - val_loss: 0.6152 - val_acc: 0.8618\n",
      "Epoch 310/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0065 - acc: 0.9999 - val_loss: 0.6165 - val_acc: 0.8616\n",
      "Epoch 311/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0064 - acc: 0.9999 - val_loss: 0.6178 - val_acc: 0.8619\n",
      "Epoch 312/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0063 - acc: 0.9999 - val_loss: 0.6191 - val_acc: 0.8620\n",
      "Epoch 313/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0063 - acc: 0.9999 - val_loss: 0.6205 - val_acc: 0.8616\n",
      "Epoch 314/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0062 - acc: 0.9999 - val_loss: 0.6218 - val_acc: 0.8616\n",
      "Epoch 315/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0062 - acc: 0.9999 - val_loss: 0.6233 - val_acc: 0.8604\n",
      "Epoch 316/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0061 - acc: 0.9999 - val_loss: 0.6245 - val_acc: 0.8610\n",
      "Epoch 317/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0060 - acc: 0.9999 - val_loss: 0.6258 - val_acc: 0.8612\n",
      "Epoch 318/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0060 - acc: 0.9999 - val_loss: 0.6272 - val_acc: 0.8602\n",
      "Epoch 319/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0059 - acc: 0.9999 - val_loss: 0.6284 - val_acc: 0.8618\n",
      "Epoch 320/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0059 - acc: 0.9999 - val_loss: 0.6299 - val_acc: 0.8604\n",
      "Epoch 321/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0058 - acc: 0.9999 - val_loss: 0.6310 - val_acc: 0.8616\n",
      "Epoch 322/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0058 - acc: 0.9999 - val_loss: 0.6324 - val_acc: 0.8604\n",
      "Epoch 323/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0057 - acc: 0.9999 - val_loss: 0.6336 - val_acc: 0.8612\n",
      "Epoch 324/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0056 - acc: 0.9999 - val_loss: 0.6357 - val_acc: 0.8604\n",
      "Epoch 325/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0056 - acc: 0.9999 - val_loss: 0.6363 - val_acc: 0.8612\n",
      "Epoch 326/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0055 - acc: 0.9999 - val_loss: 0.6379 - val_acc: 0.8615\n",
      "Epoch 327/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0055 - acc: 0.9999 - val_loss: 0.6392 - val_acc: 0.8600\n",
      "Epoch 328/1000\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0054 - acc: 0.9999 - val_loss: 0.6404 - val_acc: 0.8603\n",
      "Epoch 329/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0054 - acc: 0.9999 - val_loss: 0.6418 - val_acc: 0.8601\n",
      "Epoch 330/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0053 - acc: 0.9999 - val_loss: 0.6430 - val_acc: 0.8604\n",
      "Epoch 331/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0053 - acc: 0.9999 - val_loss: 0.6443 - val_acc: 0.8607\n",
      "Epoch 332/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0052 - acc: 0.9999 - val_loss: 0.6459 - val_acc: 0.8599\n",
      "Epoch 333/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0052 - acc: 0.9999 - val_loss: 0.6470 - val_acc: 0.8599\n",
      "Epoch 334/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0051 - acc: 0.9999 - val_loss: 0.6482 - val_acc: 0.8598\n",
      "Epoch 335/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0051 - acc: 0.9999 - val_loss: 0.6499 - val_acc: 0.8598\n",
      "Epoch 336/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0050 - acc: 0.9999 - val_loss: 0.6509 - val_acc: 0.8599\n",
      "Epoch 337/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0050 - acc: 0.9999 - val_loss: 0.6523 - val_acc: 0.8599\n",
      "Epoch 338/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0049 - acc: 0.9999 - val_loss: 0.6535 - val_acc: 0.8599\n",
      "Epoch 339/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0049 - acc: 0.9999 - val_loss: 0.6549 - val_acc: 0.8598\n",
      "Epoch 340/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0048 - acc: 0.9999 - val_loss: 0.6564 - val_acc: 0.8598\n",
      "Epoch 341/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0048 - acc: 0.9999 - val_loss: 0.6575 - val_acc: 0.8597\n",
      "Epoch 342/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0048 - acc: 0.9999 - val_loss: 0.6588 - val_acc: 0.8606\n",
      "Epoch 343/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0047 - acc: 0.9999 - val_loss: 0.6601 - val_acc: 0.8595\n",
      "Epoch 344/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0047 - acc: 0.9999 - val_loss: 0.6615 - val_acc: 0.8596\n",
      "Epoch 345/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0046 - acc: 0.9999 - val_loss: 0.6628 - val_acc: 0.8595\n",
      "Epoch 346/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0046 - acc: 0.9999 - val_loss: 0.6641 - val_acc: 0.8597\n",
      "Epoch 347/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0045 - acc: 0.9999 - val_loss: 0.6656 - val_acc: 0.8596\n",
      "Epoch 348/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0045 - acc: 0.9999 - val_loss: 0.6667 - val_acc: 0.8598\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 349/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.6683 - val_acc: 0.8594\n",
      "Epoch 350/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.6696 - val_acc: 0.8594\n",
      "Epoch 351/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0044 - acc: 0.9999 - val_loss: 0.6710 - val_acc: 0.8595\n",
      "Epoch 352/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.6722 - val_acc: 0.8593\n",
      "Epoch 353/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0043 - acc: 0.9999 - val_loss: 0.6737 - val_acc: 0.8595\n",
      "Epoch 354/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.6749 - val_acc: 0.8592\n",
      "Epoch 355/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.6763 - val_acc: 0.8591\n",
      "Epoch 356/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0042 - acc: 0.9999 - val_loss: 0.6777 - val_acc: 0.8590\n",
      "Epoch 357/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.6791 - val_acc: 0.8597\n",
      "Epoch 358/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0041 - acc: 0.9999 - val_loss: 0.6802 - val_acc: 0.8591\n",
      "Epoch 359/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.6817 - val_acc: 0.8593\n",
      "Epoch 360/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.6829 - val_acc: 0.8593\n",
      "Epoch 361/1000\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.0040 - acc: 0.9999 - val_loss: 0.6843 - val_acc: 0.8591\n",
      "Epoch 362/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.6856 - val_acc: 0.8594\n",
      "Epoch 363/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.6871 - val_acc: 0.8591\n",
      "Epoch 364/1000\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.0039 - acc: 0.9999 - val_loss: 0.6882 - val_acc: 0.8592\n",
      "Epoch 365/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.6901 - val_acc: 0.8585\n",
      "Epoch 366/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.6908 - val_acc: 0.8588\n",
      "Epoch 367/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0038 - acc: 0.9999 - val_loss: 0.6921 - val_acc: 0.8590\n",
      "Epoch 368/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.6934 - val_acc: 0.8593\n",
      "Epoch 369/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.6948 - val_acc: 0.8590\n",
      "Epoch 370/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0037 - acc: 0.9999 - val_loss: 0.6961 - val_acc: 0.8591\n",
      "Epoch 371/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.6972 - val_acc: 0.8592\n",
      "Epoch 372/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.6984 - val_acc: 0.8588\n",
      "Epoch 373/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0036 - acc: 0.9999 - val_loss: 0.6998 - val_acc: 0.8592\n",
      "Epoch 374/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0035 - acc: 0.9999 - val_loss: 0.7011 - val_acc: 0.8590\n",
      "Epoch 375/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0035 - acc: 0.9999 - val_loss: 0.7024 - val_acc: 0.8591\n",
      "Epoch 376/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 0.7037 - val_acc: 0.8590\n",
      "Epoch 377/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 0.7050 - val_acc: 0.8591\n",
      "Epoch 378/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 0.7064 - val_acc: 0.8589\n",
      "Epoch 379/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0034 - acc: 0.9999 - val_loss: 0.7076 - val_acc: 0.8590\n",
      "Epoch 380/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0033 - acc: 0.9999 - val_loss: 0.7090 - val_acc: 0.8585\n",
      "Epoch 381/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0033 - acc: 0.9999 - val_loss: 0.7103 - val_acc: 0.8587\n",
      "Epoch 382/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0033 - acc: 0.9999 - val_loss: 0.7116 - val_acc: 0.8588\n",
      "Epoch 383/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.7127 - val_acc: 0.8586\n",
      "Epoch 384/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.7141 - val_acc: 0.8590\n",
      "Epoch 385/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0032 - acc: 0.9999 - val_loss: 0.7155 - val_acc: 0.8586\n",
      "Epoch 386/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7166 - val_acc: 0.8591\n",
      "Epoch 387/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7182 - val_acc: 0.8586\n",
      "Epoch 388/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0031 - acc: 1.0000 - val_loss: 0.7193 - val_acc: 0.8585\n",
      "Epoch 389/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7205 - val_acc: 0.8584\n",
      "Epoch 390/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7219 - val_acc: 0.8584\n",
      "Epoch 391/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7232 - val_acc: 0.8583\n",
      "Epoch 392/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0030 - acc: 1.0000 - val_loss: 0.7244 - val_acc: 0.8590\n",
      "Epoch 393/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.7258 - val_acc: 0.8589\n",
      "Epoch 394/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.7270 - val_acc: 0.8589\n",
      "Epoch 395/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.7282 - val_acc: 0.8582\n",
      "Epoch 396/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0029 - acc: 1.0000 - val_loss: 0.7296 - val_acc: 0.8589\n",
      "Epoch 397/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7309 - val_acc: 0.8582\n",
      "Epoch 398/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7321 - val_acc: 0.8581\n",
      "Epoch 399/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7333 - val_acc: 0.8583\n",
      "Epoch 400/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0028 - acc: 1.0000 - val_loss: 0.7345 - val_acc: 0.8583\n",
      "Epoch 401/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7358 - val_acc: 0.8580\n",
      "Epoch 402/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7371 - val_acc: 0.8584\n",
      "Epoch 403/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7383 - val_acc: 0.8580\n",
      "Epoch 404/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0027 - acc: 1.0000 - val_loss: 0.7397 - val_acc: 0.8584\n",
      "Epoch 405/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.7410 - val_acc: 0.8579\n",
      "Epoch 406/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.7422 - val_acc: 0.8578\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 407/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.7435 - val_acc: 0.8581\n",
      "Epoch 408/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0026 - acc: 1.0000 - val_loss: 0.7448 - val_acc: 0.8579\n",
      "Epoch 409/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.7461 - val_acc: 0.8577\n",
      "Epoch 410/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.7474 - val_acc: 0.8577\n",
      "Epoch 411/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.7486 - val_acc: 0.8576\n",
      "Epoch 412/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0025 - acc: 1.0000 - val_loss: 0.7502 - val_acc: 0.8575\n",
      "Epoch 413/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.7512 - val_acc: 0.8575\n",
      "Epoch 414/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.7524 - val_acc: 0.8576\n",
      "Epoch 415/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.7537 - val_acc: 0.8575\n",
      "Epoch 416/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.7550 - val_acc: 0.8579\n",
      "Epoch 417/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0024 - acc: 1.0000 - val_loss: 0.7563 - val_acc: 0.8575\n",
      "Epoch 418/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7578 - val_acc: 0.8580\n",
      "Epoch 419/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7587 - val_acc: 0.8576\n",
      "Epoch 420/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7600 - val_acc: 0.8578\n",
      "Epoch 421/1000\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0023 - acc: 1.0000 - val_loss: 0.7613 - val_acc: 0.8575\n",
      "Epoch 422/1000\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.7626 - val_acc: 0.8573\n",
      "Epoch 423/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.7638 - val_acc: 0.8574\n",
      "Epoch 424/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.7649 - val_acc: 0.8575\n",
      "Epoch 425/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.7663 - val_acc: 0.8569\n",
      "Epoch 426/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0022 - acc: 1.0000 - val_loss: 0.7675 - val_acc: 0.8573\n",
      "Epoch 427/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.7686 - val_acc: 0.8568\n",
      "Epoch 428/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.7698 - val_acc: 0.8569\n",
      "Epoch 429/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.7711 - val_acc: 0.8570\n",
      "Epoch 430/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.7723 - val_acc: 0.8567\n",
      "Epoch 431/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0021 - acc: 1.0000 - val_loss: 0.7737 - val_acc: 0.8576\n",
      "Epoch 432/1000\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7747 - val_acc: 0.8566\n",
      "Epoch 433/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7761 - val_acc: 0.8567\n",
      "Epoch 434/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7774 - val_acc: 0.8568\n",
      "Epoch 435/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7787 - val_acc: 0.8576\n",
      "Epoch 436/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7800 - val_acc: 0.8576\n",
      "Epoch 437/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0020 - acc: 1.0000 - val_loss: 0.7810 - val_acc: 0.8565\n",
      "Epoch 438/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.7822 - val_acc: 0.8568\n",
      "Epoch 439/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.7835 - val_acc: 0.8567\n",
      "Epoch 440/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.7849 - val_acc: 0.8570\n",
      "Epoch 441/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.7858 - val_acc: 0.8566\n",
      "Epoch 442/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0019 - acc: 1.0000 - val_loss: 0.7872 - val_acc: 0.8567\n",
      "Epoch 443/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7885 - val_acc: 0.8569\n",
      "Epoch 444/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7898 - val_acc: 0.8570\n",
      "Epoch 445/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7911 - val_acc: 0.8569\n",
      "Epoch 446/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7923 - val_acc: 0.8569\n",
      "Epoch 447/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7937 - val_acc: 0.8567\n",
      "Epoch 448/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0018 - acc: 1.0000 - val_loss: 0.7949 - val_acc: 0.8567\n",
      "Epoch 449/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7962 - val_acc: 0.8567\n",
      "Epoch 450/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7976 - val_acc: 0.8569\n",
      "Epoch 451/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7985 - val_acc: 0.8564\n",
      "Epoch 452/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.7999 - val_acc: 0.8568\n",
      "Epoch 453/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8010 - val_acc: 0.8567\n",
      "Epoch 454/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8022 - val_acc: 0.8568\n",
      "Epoch 455/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0017 - acc: 1.0000 - val_loss: 0.8036 - val_acc: 0.8566\n",
      "Epoch 456/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8049 - val_acc: 0.8567\n",
      "Epoch 457/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8063 - val_acc: 0.8566\n",
      "Epoch 458/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8073 - val_acc: 0.8563\n",
      "Epoch 459/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8085 - val_acc: 0.8566\n",
      "Epoch 460/1000\n",
      "15000/15000 [==============================] - 2s 104us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8097 - val_acc: 0.8565\n",
      "Epoch 461/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0016 - acc: 1.0000 - val_loss: 0.8114 - val_acc: 0.8562\n",
      "Epoch 462/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8123 - val_acc: 0.8566\n",
      "Epoch 463/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8136 - val_acc: 0.8564\n",
      "Epoch 464/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8147 - val_acc: 0.8566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 465/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8159 - val_acc: 0.8563\n",
      "Epoch 466/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8171 - val_acc: 0.8565\n",
      "Epoch 467/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8182 - val_acc: 0.8563\n",
      "Epoch 468/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8195 - val_acc: 0.8562\n",
      "Epoch 469/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0015 - acc: 1.0000 - val_loss: 0.8209 - val_acc: 0.8562\n",
      "Epoch 470/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8221 - val_acc: 0.8563\n",
      "Epoch 471/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8232 - val_acc: 0.8562\n",
      "Epoch 472/1000\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8244 - val_acc: 0.8559\n",
      "Epoch 473/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8261 - val_acc: 0.8564\n",
      "Epoch 474/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8271 - val_acc: 0.8560\n",
      "Epoch 475/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8282 - val_acc: 0.8559\n",
      "Epoch 476/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8298 - val_acc: 0.8564\n",
      "Epoch 477/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 0.0014 - acc: 1.0000 - val_loss: 0.8305 - val_acc: 0.8561\n",
      "Epoch 478/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8318 - val_acc: 0.8559\n",
      "Epoch 479/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8328 - val_acc: 0.8564\n",
      "Epoch 480/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8342 - val_acc: 0.8560\n",
      "Epoch 481/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8356 - val_acc: 0.8561\n",
      "Epoch 482/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8365 - val_acc: 0.8564\n",
      "Epoch 483/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8378 - val_acc: 0.8559\n",
      "Epoch 484/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8392 - val_acc: 0.8556\n",
      "Epoch 485/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0013 - acc: 1.0000 - val_loss: 0.8402 - val_acc: 0.8559\n",
      "Epoch 486/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8414 - val_acc: 0.8557\n",
      "Epoch 487/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8427 - val_acc: 0.8559\n",
      "Epoch 488/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8438 - val_acc: 0.8561\n",
      "Epoch 489/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8451 - val_acc: 0.8555\n",
      "Epoch 490/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8464 - val_acc: 0.8557\n",
      "Epoch 491/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8474 - val_acc: 0.8557\n",
      "Epoch 492/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8485 - val_acc: 0.8560\n",
      "Epoch 493/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8500 - val_acc: 0.8558\n",
      "Epoch 494/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0012 - acc: 1.0000 - val_loss: 0.8512 - val_acc: 0.8556\n",
      "Epoch 495/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8522 - val_acc: 0.8558\n",
      "Epoch 496/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8534 - val_acc: 0.8557\n",
      "Epoch 497/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8544 - val_acc: 0.8559\n",
      "Epoch 498/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8560 - val_acc: 0.8557\n",
      "Epoch 499/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8570 - val_acc: 0.8556\n",
      "Epoch 500/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8582 - val_acc: 0.8556\n",
      "Epoch 501/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8595 - val_acc: 0.8557\n",
      "Epoch 502/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8607 - val_acc: 0.8558\n",
      "Epoch 503/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8619 - val_acc: 0.8556\n",
      "Epoch 504/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0011 - acc: 1.0000 - val_loss: 0.8630 - val_acc: 0.8556\n",
      "Epoch 505/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8646 - val_acc: 0.8560\n",
      "Epoch 506/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8657 - val_acc: 0.8560\n",
      "Epoch 507/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8664 - val_acc: 0.8555\n",
      "Epoch 508/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8677 - val_acc: 0.8556\n",
      "Epoch 509/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.0010 - acc: 1.0000 - val_loss: 0.8689 - val_acc: 0.8556\n",
      "Epoch 510/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 9.9928e-04 - acc: 1.0000 - val_loss: 0.8700 - val_acc: 0.8555\n",
      "Epoch 511/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 9.9056e-04 - acc: 1.0000 - val_loss: 0.8714 - val_acc: 0.8556\n",
      "Epoch 512/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 9.8233e-04 - acc: 1.0000 - val_loss: 0.8725 - val_acc: 0.8553\n",
      "Epoch 513/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 9.7230e-04 - acc: 1.0000 - val_loss: 0.8737 - val_acc: 0.8557\n",
      "Epoch 514/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 9.6360e-04 - acc: 1.0000 - val_loss: 0.8748 - val_acc: 0.8557\n",
      "Epoch 515/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 9.5714e-04 - acc: 1.0000 - val_loss: 0.8760 - val_acc: 0.8552\n",
      "Epoch 516/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 9.4593e-04 - acc: 1.0000 - val_loss: 0.8772 - val_acc: 0.8555\n",
      "Epoch 517/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 9.3735e-04 - acc: 1.0000 - val_loss: 0.8784 - val_acc: 0.8555\n",
      "Epoch 518/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 9.3015e-04 - acc: 1.0000 - val_loss: 0.8794 - val_acc: 0.8553\n",
      "Epoch 519/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 9.2104e-04 - acc: 1.0000 - val_loss: 0.8808 - val_acc: 0.8556\n",
      "Epoch 520/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 9.1300e-04 - acc: 1.0000 - val_loss: 0.8818 - val_acc: 0.8552\n",
      "Epoch 521/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 9.0541e-04 - acc: 1.0000 - val_loss: 0.8828 - val_acc: 0.8554\n",
      "Epoch 522/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 102us/step - loss: 8.9770e-04 - acc: 1.0000 - val_loss: 0.8840 - val_acc: 0.8553\n",
      "Epoch 523/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 8.8809e-04 - acc: 1.0000 - val_loss: 0.8852 - val_acc: 0.8552\n",
      "Epoch 524/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.8094e-04 - acc: 1.0000 - val_loss: 0.8863 - val_acc: 0.8552\n",
      "Epoch 525/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.7244e-04 - acc: 1.0000 - val_loss: 0.8877 - val_acc: 0.8556\n",
      "Epoch 526/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 8.6417e-04 - acc: 1.0000 - val_loss: 0.8888 - val_acc: 0.8554\n",
      "Epoch 527/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.5690e-04 - acc: 1.0000 - val_loss: 0.8898 - val_acc: 0.8551\n",
      "Epoch 528/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.4911e-04 - acc: 1.0000 - val_loss: 0.8912 - val_acc: 0.8555\n",
      "Epoch 529/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 8.4213e-04 - acc: 1.0000 - val_loss: 0.8923 - val_acc: 0.8554\n",
      "Epoch 530/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 8.3362e-04 - acc: 1.0000 - val_loss: 0.8936 - val_acc: 0.8552\n",
      "Epoch 531/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 8.2525e-04 - acc: 1.0000 - val_loss: 0.8945 - val_acc: 0.8552\n",
      "Epoch 532/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.1976e-04 - acc: 1.0000 - val_loss: 0.8957 - val_acc: 0.8549\n",
      "Epoch 533/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.1172e-04 - acc: 1.0000 - val_loss: 0.8974 - val_acc: 0.8556\n",
      "Epoch 534/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.0464e-04 - acc: 1.0000 - val_loss: 0.8981 - val_acc: 0.8552\n",
      "Epoch 535/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.9675e-04 - acc: 1.0000 - val_loss: 0.8992 - val_acc: 0.8552\n",
      "Epoch 536/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.9075e-04 - acc: 1.0000 - val_loss: 0.9005 - val_acc: 0.8553\n",
      "Epoch 537/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.8260e-04 - acc: 1.0000 - val_loss: 0.9014 - val_acc: 0.8551\n",
      "Epoch 538/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.7609e-04 - acc: 1.0000 - val_loss: 0.9030 - val_acc: 0.8556\n",
      "Epoch 539/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.6991e-04 - acc: 1.0000 - val_loss: 0.9036 - val_acc: 0.8551\n",
      "Epoch 540/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 7.6232e-04 - acc: 1.0000 - val_loss: 0.9049 - val_acc: 0.8555\n",
      "Epoch 541/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.5601e-04 - acc: 1.0000 - val_loss: 0.9059 - val_acc: 0.8549\n",
      "Epoch 542/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.4858e-04 - acc: 1.0000 - val_loss: 0.9071 - val_acc: 0.8553\n",
      "Epoch 543/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.4122e-04 - acc: 1.0000 - val_loss: 0.9081 - val_acc: 0.8547\n",
      "Epoch 544/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.3599e-04 - acc: 1.0000 - val_loss: 0.9092 - val_acc: 0.8547\n",
      "Epoch 545/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.2896e-04 - acc: 1.0000 - val_loss: 0.9104 - val_acc: 0.8550\n",
      "Epoch 546/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.2203e-04 - acc: 1.0000 - val_loss: 0.9115 - val_acc: 0.8545\n",
      "Epoch 547/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.1495e-04 - acc: 1.0000 - val_loss: 0.9126 - val_acc: 0.8546\n",
      "Epoch 548/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.0917e-04 - acc: 1.0000 - val_loss: 0.9137 - val_acc: 0.8544\n",
      "Epoch 549/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.0301e-04 - acc: 1.0000 - val_loss: 0.9151 - val_acc: 0.8554\n",
      "Epoch 550/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.9704e-04 - acc: 1.0000 - val_loss: 0.9160 - val_acc: 0.8549\n",
      "Epoch 551/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.9086e-04 - acc: 1.0000 - val_loss: 0.9173 - val_acc: 0.8549\n",
      "Epoch 552/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 6.8398e-04 - acc: 1.0000 - val_loss: 0.9183 - val_acc: 0.8546\n",
      "Epoch 553/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.7862e-04 - acc: 1.0000 - val_loss: 0.9196 - val_acc: 0.8551\n",
      "Epoch 554/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.7153e-04 - acc: 1.0000 - val_loss: 0.9206 - val_acc: 0.8547\n",
      "Epoch 555/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.6628e-04 - acc: 1.0000 - val_loss: 0.9218 - val_acc: 0.8545\n",
      "Epoch 556/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.6026e-04 - acc: 1.0000 - val_loss: 0.9228 - val_acc: 0.8544\n",
      "Epoch 557/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.5435e-04 - acc: 1.0000 - val_loss: 0.9238 - val_acc: 0.8544\n",
      "Epoch 558/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.4871e-04 - acc: 1.0000 - val_loss: 0.9252 - val_acc: 0.8547\n",
      "Epoch 559/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.4270e-04 - acc: 1.0000 - val_loss: 0.9261 - val_acc: 0.8543\n",
      "Epoch 560/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.3720e-04 - acc: 1.0000 - val_loss: 0.9271 - val_acc: 0.8544\n",
      "Epoch 561/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.3162e-04 - acc: 1.0000 - val_loss: 0.9284 - val_acc: 0.8538\n",
      "Epoch 562/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 6.2665e-04 - acc: 1.0000 - val_loss: 0.9295 - val_acc: 0.8539\n",
      "Epoch 563/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.2061e-04 - acc: 1.0000 - val_loss: 0.9307 - val_acc: 0.8540\n",
      "Epoch 564/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.1404e-04 - acc: 1.0000 - val_loss: 0.9318 - val_acc: 0.8540\n",
      "Epoch 565/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.0901e-04 - acc: 1.0000 - val_loss: 0.9328 - val_acc: 0.8543\n",
      "Epoch 566/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.0315e-04 - acc: 1.0000 - val_loss: 0.9338 - val_acc: 0.8540\n",
      "Epoch 567/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.9809e-04 - acc: 1.0000 - val_loss: 0.9347 - val_acc: 0.8541\n",
      "Epoch 568/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.9356e-04 - acc: 1.0000 - val_loss: 0.9363 - val_acc: 0.8544\n",
      "Epoch 569/1000\n",
      "15000/15000 [==============================] - 2s 105us/step - loss: 5.8729e-04 - acc: 1.0000 - val_loss: 0.9375 - val_acc: 0.8543\n",
      "Epoch 570/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.8291e-04 - acc: 1.0000 - val_loss: 0.9385 - val_acc: 0.8542\n",
      "Epoch 571/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.7798e-04 - acc: 1.0000 - val_loss: 0.9397 - val_acc: 0.8541\n",
      "Epoch 572/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.7242e-04 - acc: 1.0000 - val_loss: 0.9408 - val_acc: 0.8541\n",
      "Epoch 573/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.6737e-04 - acc: 1.0000 - val_loss: 0.9421 - val_acc: 0.8545\n",
      "Epoch 574/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.6162e-04 - acc: 1.0000 - val_loss: 0.9425 - val_acc: 0.8540\n",
      "Epoch 575/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.5732e-04 - acc: 1.0000 - val_loss: 0.9437 - val_acc: 0.8538\n",
      "Epoch 576/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 5.5255e-04 - acc: 1.0000 - val_loss: 0.9448 - val_acc: 0.8536\n",
      "Epoch 577/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 5.4820e-04 - acc: 1.0000 - val_loss: 0.9459 - val_acc: 0.8534\n",
      "Epoch 578/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.4308e-04 - acc: 1.0000 - val_loss: 0.9473 - val_acc: 0.8539\n",
      "Epoch 579/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.3734e-04 - acc: 1.0000 - val_loss: 0.9484 - val_acc: 0.8537\n",
      "Epoch 580/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 5.3335e-04 - acc: 1.0000 - val_loss: 0.9494 - val_acc: 0.8536\n",
      "Epoch 581/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.2883e-04 - acc: 1.0000 - val_loss: 0.9504 - val_acc: 0.8536\n",
      "Epoch 582/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.2432e-04 - acc: 1.0000 - val_loss: 0.9517 - val_acc: 0.8538\n",
      "Epoch 583/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.1880e-04 - acc: 1.0000 - val_loss: 0.9526 - val_acc: 0.8535\n",
      "Epoch 584/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 5.1512e-04 - acc: 1.0000 - val_loss: 0.9539 - val_acc: 0.8536\n",
      "Epoch 585/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.1060e-04 - acc: 1.0000 - val_loss: 0.9549 - val_acc: 0.8533\n",
      "Epoch 586/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.0621e-04 - acc: 1.0000 - val_loss: 0.9561 - val_acc: 0.8536\n",
      "Epoch 587/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.0147e-04 - acc: 1.0000 - val_loss: 0.9574 - val_acc: 0.8539\n",
      "Epoch 588/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 4.9679e-04 - acc: 1.0000 - val_loss: 0.9585 - val_acc: 0.8539\n",
      "Epoch 589/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.9304e-04 - acc: 1.0000 - val_loss: 0.9591 - val_acc: 0.8531\n",
      "Epoch 590/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 4.8862e-04 - acc: 1.0000 - val_loss: 0.9603 - val_acc: 0.8530\n",
      "Epoch 591/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.8411e-04 - acc: 1.0000 - val_loss: 0.9612 - val_acc: 0.8530\n",
      "Epoch 592/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.7945e-04 - acc: 1.0000 - val_loss: 0.9625 - val_acc: 0.8529\n",
      "Epoch 593/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.7586e-04 - acc: 1.0000 - val_loss: 0.9637 - val_acc: 0.8531\n",
      "Epoch 594/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.7153e-04 - acc: 1.0000 - val_loss: 0.9643 - val_acc: 0.8529\n",
      "Epoch 595/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 4.6722e-04 - acc: 1.0000 - val_loss: 0.9656 - val_acc: 0.8533\n",
      "Epoch 596/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.6347e-04 - acc: 1.0000 - val_loss: 0.9665 - val_acc: 0.8528\n",
      "Epoch 597/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.5904e-04 - acc: 1.0000 - val_loss: 0.9677 - val_acc: 0.8532\n",
      "Epoch 598/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.5518e-04 - acc: 1.0000 - val_loss: 0.9688 - val_acc: 0.8529\n",
      "Epoch 599/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.5105e-04 - acc: 1.0000 - val_loss: 0.9697 - val_acc: 0.8531\n",
      "Epoch 600/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.4698e-04 - acc: 1.0000 - val_loss: 0.9711 - val_acc: 0.8532\n",
      "Epoch 601/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 4.4293e-04 - acc: 1.0000 - val_loss: 0.9721 - val_acc: 0.8531\n",
      "Epoch 602/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.3944e-04 - acc: 1.0000 - val_loss: 0.9731 - val_acc: 0.8530\n",
      "Epoch 603/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.3497e-04 - acc: 1.0000 - val_loss: 0.9740 - val_acc: 0.8533\n",
      "Epoch 604/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.3169e-04 - acc: 1.0000 - val_loss: 0.9751 - val_acc: 0.8528\n",
      "Epoch 605/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.2809e-04 - acc: 1.0000 - val_loss: 0.9762 - val_acc: 0.8529\n",
      "Epoch 606/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.2424e-04 - acc: 1.0000 - val_loss: 0.9775 - val_acc: 0.8528\n",
      "Epoch 607/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.2013e-04 - acc: 1.0000 - val_loss: 0.9782 - val_acc: 0.8533\n",
      "Epoch 608/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.1682e-04 - acc: 1.0000 - val_loss: 0.9794 - val_acc: 0.8525\n",
      "Epoch 609/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 4.1298e-04 - acc: 1.0000 - val_loss: 0.9808 - val_acc: 0.8527\n",
      "Epoch 610/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.0962e-04 - acc: 1.0000 - val_loss: 0.9813 - val_acc: 0.8534\n",
      "Epoch 611/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.0638e-04 - acc: 1.0000 - val_loss: 0.9826 - val_acc: 0.8526\n",
      "Epoch 612/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.0225e-04 - acc: 1.0000 - val_loss: 0.9835 - val_acc: 0.8530\n",
      "Epoch 613/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.9850e-04 - acc: 1.0000 - val_loss: 0.9845 - val_acc: 0.8524\n",
      "Epoch 614/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.9555e-04 - acc: 1.0000 - val_loss: 0.9857 - val_acc: 0.8524\n",
      "Epoch 615/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.9154e-04 - acc: 1.0000 - val_loss: 0.9869 - val_acc: 0.8527\n",
      "Epoch 616/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.8861e-04 - acc: 1.0000 - val_loss: 0.9880 - val_acc: 0.8525\n",
      "Epoch 617/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.8503e-04 - acc: 1.0000 - val_loss: 0.9888 - val_acc: 0.8526\n",
      "Epoch 618/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.8203e-04 - acc: 1.0000 - val_loss: 0.9902 - val_acc: 0.8522\n",
      "Epoch 619/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.7838e-04 - acc: 1.0000 - val_loss: 0.9910 - val_acc: 0.8526\n",
      "Epoch 620/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.7518e-04 - acc: 1.0000 - val_loss: 0.9918 - val_acc: 0.8526\n",
      "Epoch 621/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.7218e-04 - acc: 1.0000 - val_loss: 0.9927 - val_acc: 0.8526\n",
      "Epoch 622/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 3.6882e-04 - acc: 1.0000 - val_loss: 0.9936 - val_acc: 0.8529\n",
      "Epoch 623/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.6586e-04 - acc: 1.0000 - val_loss: 0.9947 - val_acc: 0.8531\n",
      "Epoch 624/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.6228e-04 - acc: 1.0000 - val_loss: 0.9957 - val_acc: 0.8530\n",
      "Epoch 625/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.5988e-04 - acc: 1.0000 - val_loss: 0.9969 - val_acc: 0.8523\n",
      "Epoch 626/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.5603e-04 - acc: 1.0000 - val_loss: 0.9978 - val_acc: 0.8522\n",
      "Epoch 627/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.5328e-04 - acc: 1.0000 - val_loss: 0.9989 - val_acc: 0.8522\n",
      "Epoch 628/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.5025e-04 - acc: 1.0000 - val_loss: 1.0000 - val_acc: 0.8522\n",
      "Epoch 629/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.4749e-04 - acc: 1.0000 - val_loss: 1.0012 - val_acc: 0.8521\n",
      "Epoch 630/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 3.4447e-04 - acc: 1.0000 - val_loss: 1.0019 - val_acc: 0.8526\n",
      "Epoch 631/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.4115e-04 - acc: 1.0000 - val_loss: 1.0030 - val_acc: 0.8528\n",
      "Epoch 632/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.3851e-04 - acc: 1.0000 - val_loss: 1.0038 - val_acc: 0.8530\n",
      "Epoch 633/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.3535e-04 - acc: 1.0000 - val_loss: 1.0051 - val_acc: 0.8528\n",
      "Epoch 634/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.3271e-04 - acc: 1.0000 - val_loss: 1.0062 - val_acc: 0.8523\n",
      "Epoch 635/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.2967e-04 - acc: 1.0000 - val_loss: 1.0071 - val_acc: 0.8531\n",
      "Epoch 636/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.2680e-04 - acc: 1.0000 - val_loss: 1.0080 - val_acc: 0.8531\n",
      "Epoch 637/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.2386e-04 - acc: 1.0000 - val_loss: 1.0088 - val_acc: 0.8531\n",
      "Epoch 638/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.2144e-04 - acc: 1.0000 - val_loss: 1.0099 - val_acc: 0.8527\n",
      "Epoch 639/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.1875e-04 - acc: 1.0000 - val_loss: 1.0110 - val_acc: 0.8529\n",
      "Epoch 640/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.1557e-04 - acc: 1.0000 - val_loss: 1.0125 - val_acc: 0.8520\n",
      "Epoch 641/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.1319e-04 - acc: 1.0000 - val_loss: 1.0136 - val_acc: 0.8519\n",
      "Epoch 642/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.1054e-04 - acc: 1.0000 - val_loss: 1.0136 - val_acc: 0.8529\n",
      "Epoch 643/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.0779e-04 - acc: 1.0000 - val_loss: 1.0147 - val_acc: 0.8530\n",
      "Epoch 644/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.0524e-04 - acc: 1.0000 - val_loss: 1.0161 - val_acc: 0.8526\n",
      "Epoch 645/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.0241e-04 - acc: 1.0000 - val_loss: 1.0167 - val_acc: 0.8528\n",
      "Epoch 646/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.0004e-04 - acc: 1.0000 - val_loss: 1.0183 - val_acc: 0.8520\n",
      "Epoch 647/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.9705e-04 - acc: 1.0000 - val_loss: 1.0190 - val_acc: 0.8525\n",
      "Epoch 648/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.9492e-04 - acc: 1.0000 - val_loss: 1.0198 - val_acc: 0.8524\n",
      "Epoch 649/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.9234e-04 - acc: 1.0000 - val_loss: 1.0206 - val_acc: 0.8524\n",
      "Epoch 650/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.8997e-04 - acc: 1.0000 - val_loss: 1.0213 - val_acc: 0.8528\n",
      "Epoch 651/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.8763e-04 - acc: 1.0000 - val_loss: 1.0224 - val_acc: 0.8528\n",
      "Epoch 652/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.8465e-04 - acc: 1.0000 - val_loss: 1.0233 - val_acc: 0.8527\n",
      "Epoch 653/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.8268e-04 - acc: 1.0000 - val_loss: 1.0245 - val_acc: 0.8525\n",
      "Epoch 654/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.8031e-04 - acc: 1.0000 - val_loss: 1.0254 - val_acc: 0.8523\n",
      "Epoch 655/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.7772e-04 - acc: 1.0000 - val_loss: 1.0263 - val_acc: 0.8522\n",
      "Epoch 656/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.7543e-04 - acc: 1.0000 - val_loss: 1.0272 - val_acc: 0.8526\n",
      "Epoch 657/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.7298e-04 - acc: 1.0000 - val_loss: 1.0289 - val_acc: 0.8515\n",
      "Epoch 658/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.7064e-04 - acc: 1.0000 - val_loss: 1.0290 - val_acc: 0.8527\n",
      "Epoch 659/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.6862e-04 - acc: 1.0000 - val_loss: 1.0308 - val_acc: 0.8516\n",
      "Epoch 660/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.6648e-04 - acc: 1.0000 - val_loss: 1.0311 - val_acc: 0.8521\n",
      "Epoch 661/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.6398e-04 - acc: 1.0000 - val_loss: 1.0317 - val_acc: 0.8525\n",
      "Epoch 662/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.6140e-04 - acc: 1.0000 - val_loss: 1.0329 - val_acc: 0.8520\n",
      "Epoch 663/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.5971e-04 - acc: 1.0000 - val_loss: 1.0338 - val_acc: 0.8520\n",
      "Epoch 664/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.5727e-04 - acc: 1.0000 - val_loss: 1.0345 - val_acc: 0.8525\n",
      "Epoch 665/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.5536e-04 - acc: 1.0000 - val_loss: 1.0357 - val_acc: 0.8520\n",
      "Epoch 666/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.5323e-04 - acc: 1.0000 - val_loss: 1.0363 - val_acc: 0.8524\n",
      "Epoch 667/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.5084e-04 - acc: 1.0000 - val_loss: 1.0377 - val_acc: 0.8520\n",
      "Epoch 668/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.4901e-04 - acc: 1.0000 - val_loss: 1.0388 - val_acc: 0.8518\n",
      "Epoch 669/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.4681e-04 - acc: 1.0000 - val_loss: 1.0396 - val_acc: 0.8517\n",
      "Epoch 670/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.4457e-04 - acc: 1.0000 - val_loss: 1.0405 - val_acc: 0.8518\n",
      "Epoch 671/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.4268e-04 - acc: 1.0000 - val_loss: 1.0411 - val_acc: 0.8521\n",
      "Epoch 672/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.4046e-04 - acc: 1.0000 - val_loss: 1.0422 - val_acc: 0.8519\n",
      "Epoch 673/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.3873e-04 - acc: 1.0000 - val_loss: 1.0431 - val_acc: 0.8517\n",
      "Epoch 674/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.3673e-04 - acc: 1.0000 - val_loss: 1.0436 - val_acc: 0.8522\n",
      "Epoch 675/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.3474e-04 - acc: 1.0000 - val_loss: 1.0448 - val_acc: 0.8518\n",
      "Epoch 676/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.3256e-04 - acc: 1.0000 - val_loss: 1.0459 - val_acc: 0.8515\n",
      "Epoch 677/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.3082e-04 - acc: 1.0000 - val_loss: 1.0467 - val_acc: 0.8518\n",
      "Epoch 678/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.2888e-04 - acc: 1.0000 - val_loss: 1.0478 - val_acc: 0.8519\n",
      "Epoch 679/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.2710e-04 - acc: 1.0000 - val_loss: 1.0489 - val_acc: 0.8514\n",
      "Epoch 680/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.2512e-04 - acc: 1.0000 - val_loss: 1.0494 - val_acc: 0.8519\n",
      "Epoch 681/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 2.2331e-04 - acc: 1.0000 - val_loss: 1.0505 - val_acc: 0.8517\n",
      "Epoch 682/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.2135e-04 - acc: 1.0000 - val_loss: 1.0513 - val_acc: 0.8518\n",
      "Epoch 683/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.1943e-04 - acc: 1.0000 - val_loss: 1.0526 - val_acc: 0.8515\n",
      "Epoch 684/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.1765e-04 - acc: 1.0000 - val_loss: 1.0538 - val_acc: 0.8512\n",
      "Epoch 685/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 2.1585e-04 - acc: 1.0000 - val_loss: 1.0540 - val_acc: 0.8516\n",
      "Epoch 686/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 2.1414e-04 - acc: 1.0000 - val_loss: 1.0550 - val_acc: 0.8520\n",
      "Epoch 687/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.1243e-04 - acc: 1.0000 - val_loss: 1.0562 - val_acc: 0.8515\n",
      "Epoch 688/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.1063e-04 - acc: 1.0000 - val_loss: 1.0567 - val_acc: 0.8519\n",
      "Epoch 689/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 2.0885e-04 - acc: 1.0000 - val_loss: 1.0584 - val_acc: 0.8513\n",
      "Epoch 690/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.0712e-04 - acc: 1.0000 - val_loss: 1.0590 - val_acc: 0.8513\n",
      "Epoch 691/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 2.0547e-04 - acc: 1.0000 - val_loss: 1.0599 - val_acc: 0.8515\n",
      "Epoch 692/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.0382e-04 - acc: 1.0000 - val_loss: 1.0604 - val_acc: 0.8518\n",
      "Epoch 693/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.0201e-04 - acc: 1.0000 - val_loss: 1.0615 - val_acc: 0.8514\n",
      "Epoch 694/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 2.0026e-04 - acc: 1.0000 - val_loss: 1.0625 - val_acc: 0.8514\n",
      "Epoch 695/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.9880e-04 - acc: 1.0000 - val_loss: 1.0632 - val_acc: 0.8513\n",
      "Epoch 696/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.9719e-04 - acc: 1.0000 - val_loss: 1.0649 - val_acc: 0.8513\n",
      "Epoch 697/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.9575e-04 - acc: 1.0000 - val_loss: 1.0654 - val_acc: 0.8512\n",
      "Epoch 698/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 1.9398e-04 - acc: 1.0000 - val_loss: 1.0659 - val_acc: 0.8515\n",
      "Epoch 699/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.9209e-04 - acc: 1.0000 - val_loss: 1.0667 - val_acc: 0.8517\n",
      "Epoch 700/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.9075e-04 - acc: 1.0000 - val_loss: 1.0679 - val_acc: 0.8513\n",
      "Epoch 701/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.8935e-04 - acc: 1.0000 - val_loss: 1.0689 - val_acc: 0.8512\n",
      "Epoch 702/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 1.8770e-04 - acc: 1.0000 - val_loss: 1.0695 - val_acc: 0.8515\n",
      "Epoch 703/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.8606e-04 - acc: 1.0000 - val_loss: 1.0708 - val_acc: 0.8509\n",
      "Epoch 704/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.8454e-04 - acc: 1.0000 - val_loss: 1.0712 - val_acc: 0.8514\n",
      "Epoch 705/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.8323e-04 - acc: 1.0000 - val_loss: 1.0727 - val_acc: 0.8509\n",
      "Epoch 706/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.8180e-04 - acc: 1.0000 - val_loss: 1.0729 - val_acc: 0.8514\n",
      "Epoch 707/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.8018e-04 - acc: 1.0000 - val_loss: 1.0744 - val_acc: 0.8508\n",
      "Epoch 708/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 1.7854e-04 - acc: 1.0000 - val_loss: 1.0743 - val_acc: 0.8513\n",
      "Epoch 709/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.7728e-04 - acc: 1.0000 - val_loss: 1.0754 - val_acc: 0.8513\n",
      "Epoch 710/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.7574e-04 - acc: 1.0000 - val_loss: 1.0761 - val_acc: 0.8516\n",
      "Epoch 711/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.7443e-04 - acc: 1.0000 - val_loss: 1.0773 - val_acc: 0.8512\n",
      "Epoch 712/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.7300e-04 - acc: 1.0000 - val_loss: 1.0781 - val_acc: 0.8514\n",
      "Epoch 713/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.7166e-04 - acc: 1.0000 - val_loss: 1.0789 - val_acc: 0.8513\n",
      "Epoch 714/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.7017e-04 - acc: 1.0000 - val_loss: 1.0796 - val_acc: 0.8512\n",
      "Epoch 715/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.6888e-04 - acc: 1.0000 - val_loss: 1.0810 - val_acc: 0.8511\n",
      "Epoch 716/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.6725e-04 - acc: 1.0000 - val_loss: 1.0814 - val_acc: 0.8512\n",
      "Epoch 717/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.6608e-04 - acc: 1.0000 - val_loss: 1.0823 - val_acc: 0.8513\n",
      "Epoch 718/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.6479e-04 - acc: 1.0000 - val_loss: 1.0829 - val_acc: 0.8511\n",
      "Epoch 719/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.6343e-04 - acc: 1.0000 - val_loss: 1.0837 - val_acc: 0.8512\n",
      "Epoch 720/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.6235e-04 - acc: 1.0000 - val_loss: 1.0850 - val_acc: 0.8512\n",
      "Epoch 721/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.6081e-04 - acc: 1.0000 - val_loss: 1.0857 - val_acc: 0.8511\n",
      "Epoch 722/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.5974e-04 - acc: 1.0000 - val_loss: 1.0863 - val_acc: 0.8514\n",
      "Epoch 723/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 1.5820e-04 - acc: 1.0000 - val_loss: 1.0873 - val_acc: 0.8512\n",
      "Epoch 724/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.5687e-04 - acc: 1.0000 - val_loss: 1.0884 - val_acc: 0.8511\n",
      "Epoch 725/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.5567e-04 - acc: 1.0000 - val_loss: 1.0889 - val_acc: 0.8512\n",
      "Epoch 726/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.5434e-04 - acc: 1.0000 - val_loss: 1.0898 - val_acc: 0.8511\n",
      "Epoch 727/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.5321e-04 - acc: 1.0000 - val_loss: 1.0905 - val_acc: 0.8512\n",
      "Epoch 728/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 1.5188e-04 - acc: 1.0000 - val_loss: 1.0915 - val_acc: 0.8510\n",
      "Epoch 729/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.5081e-04 - acc: 1.0000 - val_loss: 1.0924 - val_acc: 0.8510\n",
      "Epoch 730/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.4946e-04 - acc: 1.0000 - val_loss: 1.0933 - val_acc: 0.8511\n",
      "Epoch 731/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.4851e-04 - acc: 1.0000 - val_loss: 1.0940 - val_acc: 0.8510\n",
      "Epoch 732/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 1.4732e-04 - acc: 1.0000 - val_loss: 1.0949 - val_acc: 0.8510\n",
      "Epoch 733/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.4603e-04 - acc: 1.0000 - val_loss: 1.0957 - val_acc: 0.8510\n",
      "Epoch 734/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.4497e-04 - acc: 1.0000 - val_loss: 1.0965 - val_acc: 0.8510\n",
      "Epoch 735/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.4386e-04 - acc: 1.0000 - val_loss: 1.0975 - val_acc: 0.8509\n",
      "Epoch 736/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.4264e-04 - acc: 1.0000 - val_loss: 1.0980 - val_acc: 0.8509\n",
      "Epoch 737/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.4153e-04 - acc: 1.0000 - val_loss: 1.0989 - val_acc: 0.8512\n",
      "Epoch 738/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.4034e-04 - acc: 1.0000 - val_loss: 1.0996 - val_acc: 0.8509\n",
      "Epoch 739/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.3939e-04 - acc: 1.0000 - val_loss: 1.1007 - val_acc: 0.8509\n",
      "Epoch 740/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.3811e-04 - acc: 1.0000 - val_loss: 1.1014 - val_acc: 0.8510\n",
      "Epoch 741/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.3710e-04 - acc: 1.0000 - val_loss: 1.1023 - val_acc: 0.8510\n",
      "Epoch 742/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.3614e-04 - acc: 1.0000 - val_loss: 1.1031 - val_acc: 0.8509\n",
      "Epoch 743/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.3508e-04 - acc: 1.0000 - val_loss: 1.1040 - val_acc: 0.8509\n",
      "Epoch 744/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 1.3383e-04 - acc: 1.0000 - val_loss: 1.1048 - val_acc: 0.8510\n",
      "Epoch 745/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.3276e-04 - acc: 1.0000 - val_loss: 1.1054 - val_acc: 0.8508\n",
      "Epoch 746/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.3174e-04 - acc: 1.0000 - val_loss: 1.1065 - val_acc: 0.8509\n",
      "Epoch 747/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.3081e-04 - acc: 1.0000 - val_loss: 1.1073 - val_acc: 0.8510\n",
      "Epoch 748/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.2972e-04 - acc: 1.0000 - val_loss: 1.1079 - val_acc: 0.8510\n",
      "Epoch 749/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.2870e-04 - acc: 1.0000 - val_loss: 1.1092 - val_acc: 0.8508\n",
      "Epoch 750/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.2754e-04 - acc: 1.0000 - val_loss: 1.1092 - val_acc: 0.8507\n",
      "Epoch 751/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.2688e-04 - acc: 1.0000 - val_loss: 1.1105 - val_acc: 0.8510\n",
      "Epoch 752/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.2574e-04 - acc: 1.0000 - val_loss: 1.1112 - val_acc: 0.8507\n",
      "Epoch 753/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.2465e-04 - acc: 1.0000 - val_loss: 1.1123 - val_acc: 0.8511\n",
      "Epoch 754/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.2369e-04 - acc: 1.0000 - val_loss: 1.1132 - val_acc: 0.8509\n",
      "Epoch 755/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.2284e-04 - acc: 1.0000 - val_loss: 1.1141 - val_acc: 0.8510\n",
      "Epoch 756/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.2179e-04 - acc: 1.0000 - val_loss: 1.1143 - val_acc: 0.8511\n",
      "Epoch 757/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.2089e-04 - acc: 1.0000 - val_loss: 1.1149 - val_acc: 0.8508\n",
      "Epoch 758/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.2002e-04 - acc: 1.0000 - val_loss: 1.1159 - val_acc: 0.8508\n",
      "Epoch 759/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.1903e-04 - acc: 1.0000 - val_loss: 1.1169 - val_acc: 0.8511\n",
      "Epoch 760/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.1813e-04 - acc: 1.0000 - val_loss: 1.1178 - val_acc: 0.8511\n",
      "Epoch 761/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.1727e-04 - acc: 1.0000 - val_loss: 1.1183 - val_acc: 0.8509\n",
      "Epoch 762/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.1621e-04 - acc: 1.0000 - val_loss: 1.1192 - val_acc: 0.8510\n",
      "Epoch 763/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.1546e-04 - acc: 1.0000 - val_loss: 1.1199 - val_acc: 0.8508\n",
      "Epoch 764/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.1428e-04 - acc: 1.0000 - val_loss: 1.1210 - val_acc: 0.8509\n",
      "Epoch 765/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.1362e-04 - acc: 1.0000 - val_loss: 1.1216 - val_acc: 0.8508\n",
      "Epoch 766/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.1276e-04 - acc: 1.0000 - val_loss: 1.1226 - val_acc: 0.8510\n",
      "Epoch 767/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.1196e-04 - acc: 1.0000 - val_loss: 1.1232 - val_acc: 0.8508\n",
      "Epoch 768/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.1102e-04 - acc: 1.0000 - val_loss: 1.1244 - val_acc: 0.8507\n",
      "Epoch 769/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.1029e-04 - acc: 1.0000 - val_loss: 1.1247 - val_acc: 0.8509\n",
      "Epoch 770/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.0954e-04 - acc: 1.0000 - val_loss: 1.1253 - val_acc: 0.8508\n",
      "Epoch 771/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.0860e-04 - acc: 1.0000 - val_loss: 1.1261 - val_acc: 0.8508\n",
      "Epoch 772/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.0774e-04 - acc: 1.0000 - val_loss: 1.1271 - val_acc: 0.8509\n",
      "Epoch 773/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 1.0693e-04 - acc: 1.0000 - val_loss: 1.1278 - val_acc: 0.8509\n",
      "Epoch 774/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.0616e-04 - acc: 1.0000 - val_loss: 1.1283 - val_acc: 0.8504\n",
      "Epoch 775/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.0543e-04 - acc: 1.0000 - val_loss: 1.1292 - val_acc: 0.8508\n",
      "Epoch 776/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.0428e-04 - acc: 1.0000 - val_loss: 1.1300 - val_acc: 0.8509\n",
      "Epoch 777/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.0354e-04 - acc: 1.0000 - val_loss: 1.1311 - val_acc: 0.8506\n",
      "Epoch 778/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 1.0304e-04 - acc: 1.0000 - val_loss: 1.1318 - val_acc: 0.8506\n",
      "Epoch 779/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.0215e-04 - acc: 1.0000 - val_loss: 1.1322 - val_acc: 0.8505\n",
      "Epoch 780/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 1.0139e-04 - acc: 1.0000 - val_loss: 1.1335 - val_acc: 0.8507\n",
      "Epoch 781/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 1.0045e-04 - acc: 1.0000 - val_loss: 1.1337 - val_acc: 0.8504\n",
      "Epoch 782/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 9.9964e-05 - acc: 1.0000 - val_loss: 1.1348 - val_acc: 0.8505\n",
      "Epoch 783/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 9.9153e-05 - acc: 1.0000 - val_loss: 1.1356 - val_acc: 0.8506\n",
      "Epoch 784/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 9.8305e-05 - acc: 1.0000 - val_loss: 1.1360 - val_acc: 0.8507\n",
      "Epoch 785/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 9.7565e-05 - acc: 1.0000 - val_loss: 1.1365 - val_acc: 0.8503\n",
      "Epoch 786/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 9.6815e-05 - acc: 1.0000 - val_loss: 1.1377 - val_acc: 0.8508\n",
      "Epoch 787/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 9.6154e-05 - acc: 1.0000 - val_loss: 1.1383 - val_acc: 0.8506\n",
      "Epoch 788/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 9.5410e-05 - acc: 1.0000 - val_loss: 1.1391 - val_acc: 0.8506\n",
      "Epoch 789/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 9.4728e-05 - acc: 1.0000 - val_loss: 1.1398 - val_acc: 0.8505\n",
      "Epoch 790/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 9.4036e-05 - acc: 1.0000 - val_loss: 1.1409 - val_acc: 0.8503\n",
      "Epoch 791/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 9.3361e-05 - acc: 1.0000 - val_loss: 1.1413 - val_acc: 0.8504\n",
      "Epoch 792/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 9.2660e-05 - acc: 1.0000 - val_loss: 1.1422 - val_acc: 0.8505\n",
      "Epoch 793/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 9.1949e-05 - acc: 1.0000 - val_loss: 1.1431 - val_acc: 0.8503\n",
      "Epoch 794/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 9.1278e-05 - acc: 1.0000 - val_loss: 1.1439 - val_acc: 0.8502\n",
      "Epoch 795/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 9.0574e-05 - acc: 1.0000 - val_loss: 1.1447 - val_acc: 0.8503\n",
      "Epoch 796/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 8.9761e-05 - acc: 1.0000 - val_loss: 1.1450 - val_acc: 0.8504\n",
      "Epoch 797/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.9282e-05 - acc: 1.0000 - val_loss: 1.1460 - val_acc: 0.8505\n",
      "Epoch 798/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 8.8622e-05 - acc: 1.0000 - val_loss: 1.1467 - val_acc: 0.8504\n",
      "Epoch 799/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 8.7958e-05 - acc: 1.0000 - val_loss: 1.1475 - val_acc: 0.8503\n",
      "Epoch 800/1000\n",
      "15000/15000 [==============================] - 1s 98us/step - loss: 8.7230e-05 - acc: 1.0000 - val_loss: 1.1485 - val_acc: 0.8503\n",
      "Epoch 801/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 8.6696e-05 - acc: 1.0000 - val_loss: 1.1483 - val_acc: 0.8499\n",
      "Epoch 802/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 1s 100us/step - loss: 8.6050e-05 - acc: 1.0000 - val_loss: 1.1498 - val_acc: 0.8503\n",
      "Epoch 803/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.5354e-05 - acc: 1.0000 - val_loss: 1.1499 - val_acc: 0.8503\n",
      "Epoch 804/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 8.4735e-05 - acc: 1.0000 - val_loss: 1.1507 - val_acc: 0.8503\n",
      "Epoch 805/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 8.4088e-05 - acc: 1.0000 - val_loss: 1.1521 - val_acc: 0.8499\n",
      "Epoch 806/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 8.3573e-05 - acc: 1.0000 - val_loss: 1.1524 - val_acc: 0.8504\n",
      "Epoch 807/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.2897e-05 - acc: 1.0000 - val_loss: 1.1530 - val_acc: 0.8504\n",
      "Epoch 808/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 8.2298e-05 - acc: 1.0000 - val_loss: 1.1535 - val_acc: 0.8500\n",
      "Epoch 809/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 8.1679e-05 - acc: 1.0000 - val_loss: 1.1546 - val_acc: 0.8502\n",
      "Epoch 810/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 8.1131e-05 - acc: 1.0000 - val_loss: 1.1557 - val_acc: 0.8497\n",
      "Epoch 811/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 8.0507e-05 - acc: 1.0000 - val_loss: 1.1556 - val_acc: 0.8500\n",
      "Epoch 812/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.9875e-05 - acc: 1.0000 - val_loss: 1.1563 - val_acc: 0.8500\n",
      "Epoch 813/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.9361e-05 - acc: 1.0000 - val_loss: 1.1578 - val_acc: 0.8501\n",
      "Epoch 814/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.8680e-05 - acc: 1.0000 - val_loss: 1.1583 - val_acc: 0.8499\n",
      "Epoch 815/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 7.8201e-05 - acc: 1.0000 - val_loss: 1.1582 - val_acc: 0.8501\n",
      "Epoch 816/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.7645e-05 - acc: 1.0000 - val_loss: 1.1591 - val_acc: 0.8499\n",
      "Epoch 817/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 7.7162e-05 - acc: 1.0000 - val_loss: 1.1599 - val_acc: 0.8498\n",
      "Epoch 818/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.6522e-05 - acc: 1.0000 - val_loss: 1.1604 - val_acc: 0.8501\n",
      "Epoch 819/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 7.5954e-05 - acc: 1.0000 - val_loss: 1.1612 - val_acc: 0.8501\n",
      "Epoch 820/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.5399e-05 - acc: 1.0000 - val_loss: 1.1625 - val_acc: 0.8498\n",
      "Epoch 821/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.4917e-05 - acc: 1.0000 - val_loss: 1.1629 - val_acc: 0.8495\n",
      "Epoch 822/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.4380e-05 - acc: 1.0000 - val_loss: 1.1635 - val_acc: 0.8493\n",
      "Epoch 823/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 7.3866e-05 - acc: 1.0000 - val_loss: 1.1642 - val_acc: 0.8494\n",
      "Epoch 824/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.3346e-05 - acc: 1.0000 - val_loss: 1.1647 - val_acc: 0.8499\n",
      "Epoch 825/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.2783e-05 - acc: 1.0000 - val_loss: 1.1653 - val_acc: 0.8498\n",
      "Epoch 826/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.2225e-05 - acc: 1.0000 - val_loss: 1.1666 - val_acc: 0.8494\n",
      "Epoch 827/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 7.1753e-05 - acc: 1.0000 - val_loss: 1.1669 - val_acc: 0.8497\n",
      "Epoch 828/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 7.1281e-05 - acc: 1.0000 - val_loss: 1.1677 - val_acc: 0.8496\n",
      "Epoch 829/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 7.0698e-05 - acc: 1.0000 - val_loss: 1.1684 - val_acc: 0.8497\n",
      "Epoch 830/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 7.0281e-05 - acc: 1.0000 - val_loss: 1.1689 - val_acc: 0.8498\n",
      "Epoch 831/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 6.9725e-05 - acc: 1.0000 - val_loss: 1.1696 - val_acc: 0.8499\n",
      "Epoch 832/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.9307e-05 - acc: 1.0000 - val_loss: 1.1707 - val_acc: 0.8493\n",
      "Epoch 833/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.8837e-05 - acc: 1.0000 - val_loss: 1.1713 - val_acc: 0.8493\n",
      "Epoch 834/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 6.8275e-05 - acc: 1.0000 - val_loss: 1.1715 - val_acc: 0.8496\n",
      "Epoch 835/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.7885e-05 - acc: 1.0000 - val_loss: 1.1730 - val_acc: 0.8493\n",
      "Epoch 836/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 6.7345e-05 - acc: 1.0000 - val_loss: 1.1729 - val_acc: 0.8496\n",
      "Epoch 837/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.6836e-05 - acc: 1.0000 - val_loss: 1.1741 - val_acc: 0.8492\n",
      "Epoch 838/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.6391e-05 - acc: 1.0000 - val_loss: 1.1752 - val_acc: 0.8492\n",
      "Epoch 839/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 6.5973e-05 - acc: 1.0000 - val_loss: 1.1752 - val_acc: 0.8490\n",
      "Epoch 840/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.5479e-05 - acc: 1.0000 - val_loss: 1.1760 - val_acc: 0.8490\n",
      "Epoch 841/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.5038e-05 - acc: 1.0000 - val_loss: 1.1767 - val_acc: 0.8490\n",
      "Epoch 842/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.4578e-05 - acc: 1.0000 - val_loss: 1.1772 - val_acc: 0.8490\n",
      "Epoch 843/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 6.4167e-05 - acc: 1.0000 - val_loss: 1.1778 - val_acc: 0.8493\n",
      "Epoch 844/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.3690e-05 - acc: 1.0000 - val_loss: 1.1785 - val_acc: 0.8491\n",
      "Epoch 845/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.3277e-05 - acc: 1.0000 - val_loss: 1.1793 - val_acc: 0.8489\n",
      "Epoch 846/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.2765e-05 - acc: 1.0000 - val_loss: 1.1798 - val_acc: 0.8490\n",
      "Epoch 847/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 6.2345e-05 - acc: 1.0000 - val_loss: 1.1807 - val_acc: 0.8489\n",
      "Epoch 848/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 6.1964e-05 - acc: 1.0000 - val_loss: 1.1807 - val_acc: 0.8492\n",
      "Epoch 849/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.1464e-05 - acc: 1.0000 - val_loss: 1.1815 - val_acc: 0.8489\n",
      "Epoch 850/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.1072e-05 - acc: 1.0000 - val_loss: 1.1825 - val_acc: 0.8490\n",
      "Epoch 851/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 6.0705e-05 - acc: 1.0000 - val_loss: 1.1832 - val_acc: 0.8490\n",
      "Epoch 852/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 6.0272e-05 - acc: 1.0000 - val_loss: 1.1836 - val_acc: 0.8488\n",
      "Epoch 853/1000\n",
      "15000/15000 [==============================] - 2s 145us/step - loss: 5.9869e-05 - acc: 1.0000 - val_loss: 1.1840 - val_acc: 0.8490\n",
      "Epoch 854/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 5.9442e-05 - acc: 1.0000 - val_loss: 1.1848 - val_acc: 0.8489\n",
      "Epoch 855/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.9085e-05 - acc: 1.0000 - val_loss: 1.1859 - val_acc: 0.8489\n",
      "Epoch 856/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.8647e-05 - acc: 1.0000 - val_loss: 1.1864 - val_acc: 0.8490\n",
      "Epoch 857/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 5.8317e-05 - acc: 1.0000 - val_loss: 1.1869 - val_acc: 0.8489\n",
      "Epoch 858/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.7886e-05 - acc: 1.0000 - val_loss: 1.1877 - val_acc: 0.8489\n",
      "Epoch 859/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.7468e-05 - acc: 1.0000 - val_loss: 1.1884 - val_acc: 0.8491\n",
      "Epoch 860/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.7024e-05 - acc: 1.0000 - val_loss: 1.1892 - val_acc: 0.8487\n",
      "Epoch 861/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 5.6694e-05 - acc: 1.0000 - val_loss: 1.1893 - val_acc: 0.8489\n",
      "Epoch 862/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 5.6351e-05 - acc: 1.0000 - val_loss: 1.1897 - val_acc: 0.8486\n",
      "Epoch 863/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.5953e-05 - acc: 1.0000 - val_loss: 1.1906 - val_acc: 0.8488\n",
      "Epoch 864/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.5500e-05 - acc: 1.0000 - val_loss: 1.1916 - val_acc: 0.8485\n",
      "Epoch 865/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.5212e-05 - acc: 1.0000 - val_loss: 1.1923 - val_acc: 0.8485\n",
      "Epoch 866/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.4866e-05 - acc: 1.0000 - val_loss: 1.1925 - val_acc: 0.8489\n",
      "Epoch 867/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.4478e-05 - acc: 1.0000 - val_loss: 1.1932 - val_acc: 0.8488\n",
      "Epoch 868/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.4089e-05 - acc: 1.0000 - val_loss: 1.1939 - val_acc: 0.8488\n",
      "Epoch 869/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.3731e-05 - acc: 1.0000 - val_loss: 1.1943 - val_acc: 0.8487\n",
      "Epoch 870/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 5.3362e-05 - acc: 1.0000 - val_loss: 1.1954 - val_acc: 0.8483\n",
      "Epoch 871/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.3050e-05 - acc: 1.0000 - val_loss: 1.1956 - val_acc: 0.8487\n",
      "Epoch 872/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.2680e-05 - acc: 1.0000 - val_loss: 1.1961 - val_acc: 0.8487\n",
      "Epoch 873/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.2334e-05 - acc: 1.0000 - val_loss: 1.1968 - val_acc: 0.8486\n",
      "Epoch 874/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 5.1965e-05 - acc: 1.0000 - val_loss: 1.1975 - val_acc: 0.8485\n",
      "Epoch 875/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.1640e-05 - acc: 1.0000 - val_loss: 1.1981 - val_acc: 0.8487\n",
      "Epoch 876/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 5.1317e-05 - acc: 1.0000 - val_loss: 1.1983 - val_acc: 0.8484\n",
      "Epoch 877/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 5.0967e-05 - acc: 1.0000 - val_loss: 1.1993 - val_acc: 0.8485\n",
      "Epoch 878/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 5.0630e-05 - acc: 1.0000 - val_loss: 1.1995 - val_acc: 0.8485\n",
      "Epoch 879/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 5.0335e-05 - acc: 1.0000 - val_loss: 1.2002 - val_acc: 0.8485\n",
      "Epoch 880/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.9956e-05 - acc: 1.0000 - val_loss: 1.2002 - val_acc: 0.8488\n",
      "Epoch 881/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.9698e-05 - acc: 1.0000 - val_loss: 1.2020 - val_acc: 0.8481\n",
      "Epoch 882/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.9339e-05 - acc: 1.0000 - val_loss: 1.2020 - val_acc: 0.8485\n",
      "Epoch 883/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.9032e-05 - acc: 1.0000 - val_loss: 1.2027 - val_acc: 0.8483\n",
      "Epoch 884/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.8768e-05 - acc: 1.0000 - val_loss: 1.2038 - val_acc: 0.8482\n",
      "Epoch 885/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.8369e-05 - acc: 1.0000 - val_loss: 1.2035 - val_acc: 0.8485\n",
      "Epoch 886/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.8119e-05 - acc: 1.0000 - val_loss: 1.2048 - val_acc: 0.8482\n",
      "Epoch 887/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.7730e-05 - acc: 1.0000 - val_loss: 1.2046 - val_acc: 0.8484\n",
      "Epoch 888/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.7411e-05 - acc: 1.0000 - val_loss: 1.2054 - val_acc: 0.8483\n",
      "Epoch 889/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.7134e-05 - acc: 1.0000 - val_loss: 1.2057 - val_acc: 0.8483\n",
      "Epoch 890/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.6840e-05 - acc: 1.0000 - val_loss: 1.2066 - val_acc: 0.8482\n",
      "Epoch 891/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.6552e-05 - acc: 1.0000 - val_loss: 1.2070 - val_acc: 0.8485\n",
      "Epoch 892/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.6259e-05 - acc: 1.0000 - val_loss: 1.2082 - val_acc: 0.8480\n",
      "Epoch 893/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.5937e-05 - acc: 1.0000 - val_loss: 1.2084 - val_acc: 0.8479\n",
      "Epoch 894/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.5677e-05 - acc: 1.0000 - val_loss: 1.2097 - val_acc: 0.8481\n",
      "Epoch 895/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.5349e-05 - acc: 1.0000 - val_loss: 1.2093 - val_acc: 0.8484\n",
      "Epoch 896/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.5083e-05 - acc: 1.0000 - val_loss: 1.2099 - val_acc: 0.8481\n",
      "Epoch 897/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.4851e-05 - acc: 1.0000 - val_loss: 1.2110 - val_acc: 0.8480\n",
      "Epoch 898/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.4531e-05 - acc: 1.0000 - val_loss: 1.2118 - val_acc: 0.8479\n",
      "Epoch 899/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.4217e-05 - acc: 1.0000 - val_loss: 1.2120 - val_acc: 0.8478\n",
      "Epoch 900/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.3946e-05 - acc: 1.0000 - val_loss: 1.2126 - val_acc: 0.8478\n",
      "Epoch 901/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 4.3684e-05 - acc: 1.0000 - val_loss: 1.2130 - val_acc: 0.8478\n",
      "Epoch 902/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.3377e-05 - acc: 1.0000 - val_loss: 1.2142 - val_acc: 0.8480\n",
      "Epoch 903/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.3174e-05 - acc: 1.0000 - val_loss: 1.2142 - val_acc: 0.8478\n",
      "Epoch 904/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.2876e-05 - acc: 1.0000 - val_loss: 1.2150 - val_acc: 0.8481\n",
      "Epoch 905/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.2573e-05 - acc: 1.0000 - val_loss: 1.2151 - val_acc: 0.8478\n",
      "Epoch 906/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.2361e-05 - acc: 1.0000 - val_loss: 1.2158 - val_acc: 0.8477\n",
      "Epoch 907/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.2081e-05 - acc: 1.0000 - val_loss: 1.2162 - val_acc: 0.8476\n",
      "Epoch 908/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 4.1780e-05 - acc: 1.0000 - val_loss: 1.2170 - val_acc: 0.8478\n",
      "Epoch 909/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.1564e-05 - acc: 1.0000 - val_loss: 1.2176 - val_acc: 0.8478\n",
      "Epoch 910/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.1269e-05 - acc: 1.0000 - val_loss: 1.2182 - val_acc: 0.8477\n",
      "Epoch 911/1000\n",
      "15000/15000 [==============================] - 2s 106us/step - loss: 4.1040e-05 - acc: 1.0000 - val_loss: 1.2185 - val_acc: 0.8475\n",
      "Epoch 912/1000\n",
      "15000/15000 [==============================] - 2s 106us/step - loss: 4.0771e-05 - acc: 1.0000 - val_loss: 1.2190 - val_acc: 0.8476\n",
      "Epoch 913/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 4.0502e-05 - acc: 1.0000 - val_loss: 1.2194 - val_acc: 0.8481\n",
      "Epoch 914/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 105us/step - loss: 4.0309e-05 - acc: 1.0000 - val_loss: 1.2202 - val_acc: 0.8477\n",
      "Epoch 915/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 4.0013e-05 - acc: 1.0000 - val_loss: 1.2207 - val_acc: 0.8478\n",
      "Epoch 916/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.9773e-05 - acc: 1.0000 - val_loss: 1.2213 - val_acc: 0.8476\n",
      "Epoch 917/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.9563e-05 - acc: 1.0000 - val_loss: 1.2221 - val_acc: 0.8477\n",
      "Epoch 918/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 3.9326e-05 - acc: 1.0000 - val_loss: 1.2226 - val_acc: 0.8477\n",
      "Epoch 919/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.9051e-05 - acc: 1.0000 - val_loss: 1.2233 - val_acc: 0.8476\n",
      "Epoch 920/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.8850e-05 - acc: 1.0000 - val_loss: 1.2235 - val_acc: 0.8479\n",
      "Epoch 921/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.8597e-05 - acc: 1.0000 - val_loss: 1.2245 - val_acc: 0.8476\n",
      "Epoch 922/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 3.8379e-05 - acc: 1.0000 - val_loss: 1.2245 - val_acc: 0.8479\n",
      "Epoch 923/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.8125e-05 - acc: 1.0000 - val_loss: 1.2256 - val_acc: 0.8475\n",
      "Epoch 924/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.7883e-05 - acc: 1.0000 - val_loss: 1.2254 - val_acc: 0.8480\n",
      "Epoch 925/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.7680e-05 - acc: 1.0000 - val_loss: 1.2259 - val_acc: 0.8479\n",
      "Epoch 926/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.7436e-05 - acc: 1.0000 - val_loss: 1.2270 - val_acc: 0.8476\n",
      "Epoch 927/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.7244e-05 - acc: 1.0000 - val_loss: 1.2275 - val_acc: 0.8476\n",
      "Epoch 928/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.6951e-05 - acc: 1.0000 - val_loss: 1.2280 - val_acc: 0.8476\n",
      "Epoch 929/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.6792e-05 - acc: 1.0000 - val_loss: 1.2279 - val_acc: 0.8478\n",
      "Epoch 930/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.6537e-05 - acc: 1.0000 - val_loss: 1.2292 - val_acc: 0.8476\n",
      "Epoch 931/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.6345e-05 - acc: 1.0000 - val_loss: 1.2288 - val_acc: 0.8478\n",
      "Epoch 932/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 3.6157e-05 - acc: 1.0000 - val_loss: 1.2295 - val_acc: 0.8479\n",
      "Epoch 933/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.5913e-05 - acc: 1.0000 - val_loss: 1.2303 - val_acc: 0.8480\n",
      "Epoch 934/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.5724e-05 - acc: 1.0000 - val_loss: 1.2309 - val_acc: 0.8477\n",
      "Epoch 935/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.5500e-05 - acc: 1.0000 - val_loss: 1.2311 - val_acc: 0.8480\n",
      "Epoch 936/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.5295e-05 - acc: 1.0000 - val_loss: 1.2320 - val_acc: 0.8476\n",
      "Epoch 937/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.5074e-05 - acc: 1.0000 - val_loss: 1.2323 - val_acc: 0.8480\n",
      "Epoch 938/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.4857e-05 - acc: 1.0000 - val_loss: 1.2325 - val_acc: 0.8482\n",
      "Epoch 939/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.4654e-05 - acc: 1.0000 - val_loss: 1.2343 - val_acc: 0.8477\n",
      "Epoch 940/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.4486e-05 - acc: 1.0000 - val_loss: 1.2343 - val_acc: 0.8478\n",
      "Epoch 941/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.4230e-05 - acc: 1.0000 - val_loss: 1.2339 - val_acc: 0.8483\n",
      "Epoch 942/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.4057e-05 - acc: 1.0000 - val_loss: 1.2349 - val_acc: 0.8479\n",
      "Epoch 943/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.3878e-05 - acc: 1.0000 - val_loss: 1.2351 - val_acc: 0.8479\n",
      "Epoch 944/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.3722e-05 - acc: 1.0000 - val_loss: 1.2360 - val_acc: 0.8478\n",
      "Epoch 945/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.3478e-05 - acc: 1.0000 - val_loss: 1.2363 - val_acc: 0.8482\n",
      "Epoch 946/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.3319e-05 - acc: 1.0000 - val_loss: 1.2369 - val_acc: 0.8479\n",
      "Epoch 947/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.3119e-05 - acc: 1.0000 - val_loss: 1.2377 - val_acc: 0.8480\n",
      "Epoch 948/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.2925e-05 - acc: 1.0000 - val_loss: 1.2382 - val_acc: 0.8479\n",
      "Epoch 949/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.2720e-05 - acc: 1.0000 - val_loss: 1.2379 - val_acc: 0.8487\n",
      "Epoch 950/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.2553e-05 - acc: 1.0000 - val_loss: 1.2393 - val_acc: 0.8481\n",
      "Epoch 951/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.2286e-05 - acc: 1.0000 - val_loss: 1.2391 - val_acc: 0.8482\n",
      "Epoch 952/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.2190e-05 - acc: 1.0000 - val_loss: 1.2404 - val_acc: 0.8480\n",
      "Epoch 953/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.1975e-05 - acc: 1.0000 - val_loss: 1.2410 - val_acc: 0.8476\n",
      "Epoch 954/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 3.1791e-05 - acc: 1.0000 - val_loss: 1.2415 - val_acc: 0.8474\n",
      "Epoch 955/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.1634e-05 - acc: 1.0000 - val_loss: 1.2413 - val_acc: 0.8479\n",
      "Epoch 956/1000\n",
      "15000/15000 [==============================] - 2s 103us/step - loss: 3.1421e-05 - acc: 1.0000 - val_loss: 1.2416 - val_acc: 0.8481\n",
      "Epoch 957/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.1250e-05 - acc: 1.0000 - val_loss: 1.2422 - val_acc: 0.8483\n",
      "Epoch 958/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 3.1090e-05 - acc: 1.0000 - val_loss: 1.2431 - val_acc: 0.8480\n",
      "Epoch 959/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.0904e-05 - acc: 1.0000 - val_loss: 1.2436 - val_acc: 0.8480\n",
      "Epoch 960/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.0745e-05 - acc: 1.0000 - val_loss: 1.2441 - val_acc: 0.8480\n",
      "Epoch 961/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.0561e-05 - acc: 1.0000 - val_loss: 1.2446 - val_acc: 0.8480\n",
      "Epoch 962/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.0358e-05 - acc: 1.0000 - val_loss: 1.2448 - val_acc: 0.8479\n",
      "Epoch 963/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 3.0218e-05 - acc: 1.0000 - val_loss: 1.2452 - val_acc: 0.8479\n",
      "Epoch 964/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 3.0046e-05 - acc: 1.0000 - val_loss: 1.2464 - val_acc: 0.8477\n",
      "Epoch 965/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.9879e-05 - acc: 1.0000 - val_loss: 1.2468 - val_acc: 0.8478\n",
      "Epoch 966/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.9701e-05 - acc: 1.0000 - val_loss: 1.2475 - val_acc: 0.8477\n",
      "Epoch 967/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.9556e-05 - acc: 1.0000 - val_loss: 1.2476 - val_acc: 0.8480\n",
      "Epoch 968/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.9392e-05 - acc: 1.0000 - val_loss: 1.2484 - val_acc: 0.8478\n",
      "Epoch 969/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.9190e-05 - acc: 1.0000 - val_loss: 1.2490 - val_acc: 0.8479\n",
      "Epoch 970/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15000/15000 [==============================] - 2s 103us/step - loss: 2.9051e-05 - acc: 1.0000 - val_loss: 1.2490 - val_acc: 0.8480\n",
      "Epoch 971/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.8873e-05 - acc: 1.0000 - val_loss: 1.2493 - val_acc: 0.8479\n",
      "Epoch 972/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.8703e-05 - acc: 1.0000 - val_loss: 1.2492 - val_acc: 0.8484\n",
      "Epoch 973/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.8578e-05 - acc: 1.0000 - val_loss: 1.2500 - val_acc: 0.8479\n",
      "Epoch 974/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.8397e-05 - acc: 1.0000 - val_loss: 1.2511 - val_acc: 0.8482\n",
      "Epoch 975/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.8240e-05 - acc: 1.0000 - val_loss: 1.2509 - val_acc: 0.8480\n",
      "Epoch 976/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.8103e-05 - acc: 1.0000 - val_loss: 1.2514 - val_acc: 0.8480\n",
      "Epoch 977/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.7940e-05 - acc: 1.0000 - val_loss: 1.2519 - val_acc: 0.8481\n",
      "Epoch 978/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.7806e-05 - acc: 1.0000 - val_loss: 1.2529 - val_acc: 0.8481\n",
      "Epoch 979/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 2.7624e-05 - acc: 1.0000 - val_loss: 1.2527 - val_acc: 0.8484\n",
      "Epoch 980/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.7503e-05 - acc: 1.0000 - val_loss: 1.2532 - val_acc: 0.8487\n",
      "Epoch 981/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.7376e-05 - acc: 1.0000 - val_loss: 1.2544 - val_acc: 0.8481\n",
      "Epoch 982/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.7190e-05 - acc: 1.0000 - val_loss: 1.2545 - val_acc: 0.8482\n",
      "Epoch 983/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.7037e-05 - acc: 1.0000 - val_loss: 1.2553 - val_acc: 0.8480\n",
      "Epoch 984/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.6930e-05 - acc: 1.0000 - val_loss: 1.2555 - val_acc: 0.8481\n",
      "Epoch 985/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.6731e-05 - acc: 1.0000 - val_loss: 1.2549 - val_acc: 0.8484\n",
      "Epoch 986/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.6635e-05 - acc: 1.0000 - val_loss: 1.2559 - val_acc: 0.8478\n",
      "Epoch 987/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.6502e-05 - acc: 1.0000 - val_loss: 1.2566 - val_acc: 0.8480\n",
      "Epoch 988/1000\n",
      "15000/15000 [==============================] - 2s 100us/step - loss: 2.6346e-05 - acc: 1.0000 - val_loss: 1.2572 - val_acc: 0.8482\n",
      "Epoch 989/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.6236e-05 - acc: 1.0000 - val_loss: 1.2574 - val_acc: 0.8481\n",
      "Epoch 990/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.6066e-05 - acc: 1.0000 - val_loss: 1.2580 - val_acc: 0.8481\n",
      "Epoch 991/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 2.5919e-05 - acc: 1.0000 - val_loss: 1.2595 - val_acc: 0.8483\n",
      "Epoch 992/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.5825e-05 - acc: 1.0000 - val_loss: 1.2588 - val_acc: 0.8480\n",
      "Epoch 993/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.5672e-05 - acc: 1.0000 - val_loss: 1.2599 - val_acc: 0.8482\n",
      "Epoch 994/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.5551e-05 - acc: 1.0000 - val_loss: 1.2598 - val_acc: 0.8480\n",
      "Epoch 995/1000\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 2.5384e-05 - acc: 1.0000 - val_loss: 1.2601 - val_acc: 0.8484\n",
      "Epoch 996/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.5258e-05 - acc: 1.0000 - val_loss: 1.2606 - val_acc: 0.8483\n",
      "Epoch 997/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.5129e-05 - acc: 1.0000 - val_loss: 1.2610 - val_acc: 0.8484\n",
      "Epoch 998/1000\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 2.4971e-05 - acc: 1.0000 - val_loss: 1.2619 - val_acc: 0.8478\n",
      "Epoch 999/1000\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 2.4857e-05 - acc: 1.0000 - val_loss: 1.2617 - val_acc: 0.8484\n",
      "Epoch 1000/1000\n",
      "15000/15000 [==============================] - 2s 102us/step - loss: 2.4731e-05 - acc: 1.0000 - val_loss: 1.2625 - val_acc: 0.8481\n",
      "25000/25000 [==============================] - 2s 92us/step\n",
      "最終結果： [1.3563586115932464, 0.83528]\n",
      "正解率： 61.141929030418396 %\n"
     ]
    }
   ],
   "source": [
    "# テスト：簡単なネットワークで1000エポック学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=1000, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 15000 samples, validate on 10000 samples\n",
      "Epoch 1/4\n",
      "15000/15000 [==============================] - 2s 134us/step - loss: 0.6116 - acc: 0.7454 - val_loss: 0.5600 - val_acc: 0.8127\n",
      "Epoch 2/4\n",
      "15000/15000 [==============================] - 1s 100us/step - loss: 0.5145 - acc: 0.8449 - val_loss: 0.4972 - val_acc: 0.8372\n",
      "Epoch 3/4\n",
      "15000/15000 [==============================] - 2s 101us/step - loss: 0.4538 - acc: 0.8660 - val_loss: 0.4523 - val_acc: 0.8520\n",
      "Epoch 4/4\n",
      "15000/15000 [==============================] - 1s 99us/step - loss: 0.4085 - acc: 0.8788 - val_loss: 0.4180 - val_acc: 0.8612\n",
      "25000/25000 [==============================] - 2s 87us/step\n",
      "最終結果： [0.4288048528003693, 0.85724]\n",
      "正解率： 63.6765718460083 %\n"
     ]
    }
   ],
   "source": [
    "# テスト：簡単なネットワークで4エポック学習\n",
    "model = models.Sequential()\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "model.fit(partial_x_train, partial_y_train, epochs=4, batch_size=512, validation_data=(x_val, y_val))\n",
    "results = model.evaluate(x_test, y_test)\n",
    "print(\"最終結果：\", results)\n",
    "y_pred = model.predict(x_test)\n",
    "print(\"正解率：\", (1. - np.sqrt(mean_squared_error(y_test, y_pred))) * 100, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
